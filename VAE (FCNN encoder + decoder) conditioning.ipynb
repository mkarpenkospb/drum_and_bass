{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация полифонической музыки с кондишнингом\n",
    "\n",
    "В этой версии используется VAE. Энкодер -- двухслойная полносвязная нейронная сеть, декодер -- зеркальная двухслойная полносвязная нейронная сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем torch и numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем также пользовательский импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_patterns import data_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_height = 64\n",
    "drum_width = 14\n",
    "melody_width = 36\n",
    "data_width = drum_width + melody_width\n",
    "data_size = data_height*data_width\n",
    "patterns_file = \"decode_patterns/patterns.pairs.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "drum, bass = data_conversion.make_lstm_dataset_conditioning(height=data_height,\n",
    "                                                            limit=1000,\n",
    "                                                            patterns_file=patterns_file,\n",
    "                                                            mono=False)\n",
    "# print(drum[0])\n",
    "# drum, bass = np.array(drum), np.array(bass)\n",
    "# print(drum[0])\n",
    "\n",
    "# define shuffling of dataset\n",
    "def shuffle(A, B, p=0.8):\n",
    "    # take 80% to training, other to testing\n",
    "    AB = list(zip(A, B))\n",
    "    L = len(AB)\n",
    "    pivot = int(p*L)\n",
    "    random.shuffle(AB)\n",
    "    yield [p[0] for p in AB[:pivot]]\n",
    "    yield [p[1] for p in AB[:pivot]]\n",
    "    yield [p[0] for p in AB[pivot:]]\n",
    "    yield [p[1] for p in AB[pivot:]]\n",
    "    \n",
    "    \n",
    "# we can select here a validation set\n",
    "drum, bass, drum_validation, bass_validation = shuffle(drum, bass)\n",
    "    \n",
    "# and we can shuffle train and test set like this:\n",
    "# drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumpyImage(image=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), tempo=96, instrument=81, denominator=1, min_note=60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bass[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель определим в самом простом варианте, который только можно себе представить -- как в примере с конечным автоматом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder = LSTM\n",
    "# Decoder = FCNN\n",
    "class DrumNBass_FFNN_to_FFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, data_height, drum_width, melody_width):\n",
    "        super(DrumNBass_FFNN_to_FFNN, self).__init__()\n",
    "        \n",
    "        self.data_height = data_height\n",
    "        self.drum_width = drum_width\n",
    "        self.melody_width = melody_width\n",
    "        self.condition_size = 2 # размер подмешиваемого conditioning\n",
    "        \n",
    "        input_dim = data_height*drum_width\n",
    "        latent_dim = 4\n",
    "        hidden_dim = (input_dim + 2*latent_dim) // 3\n",
    "        output_dim = data_height*melody_width\n",
    "        \n",
    "        # Linear function 1: 128 * 14 = 1792 --> 2048\n",
    "        # веса накидываются тут\n",
    "        self.fc1 = nn.Linear(input_dim + self.condition_size, hidden_dim)\n",
    "#         nn.init.normal_(self.fc1.weight, mean=1.5, std=1.0)\n",
    "        # решение по весам\n",
    "        self.relu1 = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         nn.init.normal_(self.fc2.weight, mean=1.5, std=1.0)\n",
    "        self.relu2 = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        # Linear function 31: 2048 --> 4\n",
    "        # для средних значений\n",
    "        self.fc31 = nn.Linear(hidden_dim, latent_dim)\n",
    "        # Non-linearity 31\n",
    "        self.relu31 = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        # Linear function 22: 2048 --> 4\n",
    "        # для стандартных отклонений\n",
    "        self.fc32 = nn.Linear(hidden_dim, latent_dim)\n",
    "        # Non-linearity 22\n",
    "        self.relu32 = nn.Sigmoid()\n",
    "\n",
    "        # Linear function 4: 4 --> 2048\n",
    "        self.fc4 = nn.Linear(latent_dim + self.condition_size, hidden_dim)\n",
    "#         nn.init.normal_(self.fc4.weight, mean=1.5, std=1.0)\n",
    "        # Non-linearity 4\n",
    "        self.relu4 = nn.Sigmoid()\n",
    "        \n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         nn.init.normal_(self.fc5.weight, mean=1.5, std=1.0)\n",
    "        self.relu5 = nn.Sigmoid()\n",
    "\n",
    "        # Linear function 6 (readout): 2048 --> 128 * 36 = 4608\n",
    "        self.fc6 = nn.Linear(hidden_dim, output_dim)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def encoder(self, x, cond):\n",
    "        out = torch.cat((x, cond), axis=1) # добавляем conditioning\n",
    "        # Linear function 1\n",
    "        out = self.fc1(out)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        \n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 31\n",
    "        mu = self.fc31(out)\n",
    "        # Non-linearity 31\n",
    "        mu = self.relu31(mu)\n",
    "        \n",
    "        \n",
    "        # Linear function 22\n",
    "        logvar = self.fc32(out)\n",
    "        # Non-linearity 22\n",
    "        logvar = self.relu32(logvar)\n",
    "        \n",
    "        return mu, logvar\n",
    "    \n",
    "    # reference:\n",
    "    # https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    # end reference\n",
    "    \n",
    "    def decoder(self, x, cond):\n",
    "        out = torch.cat((x, cond), axis=1) # добавляем conditioning\n",
    "        # Linear function 4\n",
    "        out = self.fc4(out)\n",
    "        # Non-linearity 4\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        # Linear function 5\n",
    "        out = self.fc5(out)\n",
    "        # Non-linearity 5\n",
    "        out = self.relu5(out)\n",
    "\n",
    "        # Linear function 6 (readout)\n",
    "        out = self.fc6(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_images(input):\n",
    "        return torch.tensor(list(map(lambda p: p.image.flatten(), input)), dtype=torch.float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_conditionings(input):\n",
    "        return torch.tensor(list(map(lambda p: [p.tempo, p.instrument], input)), dtype=torch.float)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # добавляем conditioning\n",
    "        conditionings = self.get_conditionings(x)\n",
    "        images = self.get_images(x)\n",
    "        mean, logvar = self.encoder(images, conditionings)\n",
    "        # генерируем случайную точку в латентном пространстве\n",
    "        result = self.reparameterize(mean, logvar)\n",
    "        result = self.decoder(result, conditionings)\n",
    "        return result.view((-1, self.data_height, self.melody_width)), mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# часть обучения\n",
    "dnb_ffnn = DrumNBass_FFNN_to_FFNN(data_height, drum_width, melody_width)\n",
    "\n",
    "# criterion = nn.MSELoss() # -- с этим всё работает (точнее, работало)\n",
    "# criterion = nn.NLLLoss() # -- этот товарищ требует, чтобы LSTM выдавал классы,\n",
    "# criterion = nn.CrossEntropyLoss() # и этот тоже\n",
    "# (числа от 0 до C-1), но как всё-таки его заставить это делать?...\n",
    "\n",
    "# оценим также и разнообразие мелодии по её.. дисперсии?)\n",
    "# def melody_variety(melody):\n",
    "#     return 1/(1 + (melody.sum(axis=2) > 1).int())\n",
    "\n",
    "# на самом деле, попробуем функцию потерь взять из VAE\n",
    "\n",
    "# Reference: https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def reconstruction_KL_loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = optim.Adam(dnb_ffnn.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(dnb_ffnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как модель форвардится на один пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 36])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_ffnn.forward([drum_validation[16], drum_validation[14], drum_validation[43]])[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bass_validation[16].image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найденные баги и их решения:\n",
    "\n",
    "https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ\n",
    "\n",
    "https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss/49209628\n",
    "\n",
    "https://stackoverflow.com/questions/56243672/expected-target-size-50-88-got-torch-size50-288-88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle_every_epoch is on\n",
      "Epoch #0\n",
      "[1,     1] train loss: 25859.5820312\n",
      "[1,     6] train loss: 15359.7307943\n",
      "[1,    11] train loss: 6862.5083008\n",
      "[1,    16] train loss: 2781.9050700\n",
      "[1,    21] train loss: 1802.7088623\n",
      "[1,    26] train loss: 1681.7985636\n",
      "[1,    31] train loss: 1697.6074015\n",
      "[1,    36] train loss: 1607.6613363\n",
      "[1,    40] train loss: 1501.6092285\n",
      "Epoch #1\n",
      "[2,     1] train loss: 1718.7019043\n",
      "[2,     6] train loss: 1461.6218058\n",
      "[2,    11] train loss: 1457.8783976\n",
      "[2,    16] train loss: 1568.3226725\n",
      "[2,    21] train loss: 1488.8759155\n",
      "[2,    26] train loss: 1401.9906820\n",
      "[2,    31] train loss: 1543.1268514\n",
      "[2,    36] train loss: 1551.5752970\n",
      "[2,    40] train loss: 1416.9201904\n",
      "Epoch #2\n",
      "[3,     1] train loss: 1871.4420166\n",
      "[3,     6] train loss: 1494.6694539\n",
      "[3,    11] train loss: 1390.1277466\n",
      "[3,    16] train loss: 1452.9575602\n",
      "[3,    21] train loss: 1517.0816854\n",
      "[3,    26] train loss: 1389.2742920\n",
      "[3,    31] train loss: 1466.0305176\n",
      "[3,    36] train loss: 1462.5816854\n",
      "[3,    40] train loss: 1486.8143311\n",
      "Epoch #3\n",
      "[4,     1] train loss: 1614.5853271\n",
      "[4,     6] train loss: 1529.8609823\n",
      "[4,    11] train loss: 1387.7249146\n",
      "[4,    16] train loss: 1518.7918498\n",
      "[4,    21] train loss: 1465.0673828\n",
      "[4,    26] train loss: 1495.9083252\n",
      "[4,    31] train loss: 1400.5088501\n",
      "[4,    36] train loss: 1438.9674683\n",
      "[4,    40] train loss: 1386.6055420\n",
      "Epoch #4\n",
      "[5,     1] train loss: 1643.3997803\n",
      "[5,     6] train loss: 1506.6919556\n",
      "[5,    11] train loss: 1481.8778076\n",
      "[5,    16] train loss: 1406.0083618\n",
      "[5,    21] train loss: 1468.0761312\n",
      "[5,    26] train loss: 1514.7205811\n",
      "[5,    31] train loss: 1534.6044922\n",
      "[5,    36] train loss: 1445.9709880\n",
      "[5,    40] train loss: 1346.4229492\n",
      "Epoch #5\n",
      "[6,     1] train loss: 1745.9227295\n",
      "[6,     6] train loss: 1529.2035522\n",
      "[6,    11] train loss: 1428.8323771\n",
      "[6,    16] train loss: 1542.2516276\n",
      "[6,    21] train loss: 1390.1372274\n",
      "[6,    26] train loss: 1467.4848429\n",
      "[6,    31] train loss: 1428.3514404\n",
      "[6,    36] train loss: 1533.1785889\n",
      "[6,    40] train loss: 1343.5781738\n",
      "Epoch #6\n",
      "[7,     1] train loss: 2040.1362305\n",
      "[7,     6] train loss: 1477.7344157\n",
      "[7,    11] train loss: 1371.7848714\n",
      "[7,    16] train loss: 1477.2710775\n",
      "[7,    21] train loss: 1463.6420492\n",
      "[7,    26] train loss: 1368.3295695\n",
      "[7,    31] train loss: 1513.0706991\n",
      "[7,    36] train loss: 1375.6531372\n",
      "[7,    40] train loss: 1432.4559326\n",
      "Epoch #7\n",
      "[8,     1] train loss: 1496.5798340\n",
      "[8,     6] train loss: 1481.8406169\n",
      "[8,    11] train loss: 1287.9580485\n",
      "[8,    16] train loss: 1563.4597168\n",
      "[8,    21] train loss: 1404.6847127\n",
      "[8,    26] train loss: 1547.0519613\n",
      "[8,    31] train loss: 1455.5403442\n",
      "[8,    36] train loss: 1439.2753703\n",
      "[8,    40] train loss: 1404.6822754\n",
      "Epoch #8\n",
      "[9,     1] train loss: 1871.2586670\n",
      "[9,     6] train loss: 1440.5276693\n",
      "[9,    11] train loss: 1394.5062866\n",
      "[9,    16] train loss: 1406.9474487\n",
      "[9,    21] train loss: 1390.1207886\n",
      "[9,    26] train loss: 1462.0344442\n",
      "[9,    31] train loss: 1594.3117676\n",
      "[9,    36] train loss: 1491.9216715\n",
      "[9,    40] train loss: 1351.6949463\n",
      "Epoch #9\n",
      "[10,     1] train loss: 1597.7390137\n",
      "[10,     6] train loss: 1446.7175903\n",
      "[10,    11] train loss: 1414.7768555\n",
      "[10,    16] train loss: 1413.7765299\n",
      "[10,    21] train loss: 1363.7532756\n",
      "[10,    26] train loss: 1467.8753662\n",
      "[10,    31] train loss: 1528.5929565\n",
      "[10,    36] train loss: 1513.6413778\n",
      "[10,    40] train loss: 1454.7727295\n",
      "Epoch #10\n",
      "[11,     1] train loss: 1816.5764160\n",
      "[11,     6] train loss: 1440.7650146\n",
      "[11,    11] train loss: 1368.1274211\n",
      "[11,    16] train loss: 1475.6115316\n",
      "[11,    21] train loss: 1422.5482178\n",
      "[11,    26] train loss: 1430.9926758\n",
      "[11,    31] train loss: 1486.4245809\n",
      "[11,    36] train loss: 1544.8130697\n",
      "[11,    40] train loss: 1463.5473877\n",
      "Epoch #11\n",
      "[12,     1] train loss: 1540.3051758\n",
      "[12,     6] train loss: 1515.2622884\n",
      "[12,    11] train loss: 1383.9368896\n",
      "[12,    16] train loss: 1350.6698608\n",
      "[12,    21] train loss: 1487.2015177\n",
      "[12,    26] train loss: 1498.9669189\n",
      "[12,    31] train loss: 1506.4214884\n",
      "[12,    36] train loss: 1333.8787435\n",
      "[12,    40] train loss: 1365.4731934\n",
      "Epoch #12\n",
      "[13,     1] train loss: 1833.5914307\n",
      "[13,     6] train loss: 1482.3161011\n",
      "[13,    11] train loss: 1520.6486206\n",
      "[13,    16] train loss: 1334.3511963\n",
      "[13,    21] train loss: 1425.0142415\n",
      "[13,    26] train loss: 1408.4988607\n",
      "[13,    31] train loss: 1374.3115031\n",
      "[13,    36] train loss: 1572.6740519\n",
      "[13,    40] train loss: 1365.1252197\n",
      "Epoch #13\n",
      "[14,     1] train loss: 1961.0800781\n",
      "[14,     6] train loss: 1366.3362020\n",
      "[14,    11] train loss: 1358.0069173\n",
      "[14,    16] train loss: 1487.2741496\n",
      "[14,    21] train loss: 1411.8817139\n",
      "[14,    26] train loss: 1475.1674398\n",
      "[14,    31] train loss: 1522.4220785\n",
      "[14,    36] train loss: 1458.9937134\n",
      "[14,    40] train loss: 1366.2746338\n",
      "Epoch #14\n",
      "[15,     1] train loss: 1559.5054932\n",
      "[15,     6] train loss: 1382.4901733\n",
      "[15,    11] train loss: 1454.8380941\n",
      "[15,    16] train loss: 1517.9270223\n",
      "[15,    21] train loss: 1432.9367269\n",
      "[15,    26] train loss: 1404.0746053\n",
      "[15,    31] train loss: 1374.1094157\n",
      "[15,    36] train loss: 1574.8041789\n",
      "[15,    40] train loss: 1388.2490479\n",
      "Epoch #15\n",
      "[16,     1] train loss: 1763.3276367\n",
      "[16,     6] train loss: 1505.9357910\n",
      "[16,    11] train loss: 1481.1001383\n",
      "[16,    16] train loss: 1476.9846598\n",
      "[16,    21] train loss: 1496.7831828\n",
      "[16,    26] train loss: 1463.5714722\n",
      "[16,    31] train loss: 1392.2103271\n",
      "[16,    36] train loss: 1395.4645996\n",
      "[16,    40] train loss: 1288.8712158\n",
      "Epoch #16\n",
      "[17,     1] train loss: 1397.2088623\n",
      "[17,     6] train loss: 1508.2357788\n",
      "[17,    11] train loss: 1444.4700317\n",
      "[17,    16] train loss: 1432.7007853\n",
      "[17,    21] train loss: 1379.6542765\n",
      "[17,    26] train loss: 1516.7036336\n",
      "[17,    31] train loss: 1417.2213338\n",
      "[17,    36] train loss: 1459.2098185\n",
      "[17,    40] train loss: 1292.0290283\n",
      "Epoch #17\n",
      "[18,     1] train loss: 1948.9301758\n",
      "[18,     6] train loss: 1329.7893270\n",
      "[18,    11] train loss: 1370.5568848\n",
      "[18,    16] train loss: 1431.0874837\n",
      "[18,    21] train loss: 1481.5822754\n",
      "[18,    26] train loss: 1482.0310059\n",
      "[18,    31] train loss: 1521.0939941\n",
      "[18,    36] train loss: 1378.6318970\n",
      "[18,    40] train loss: 1427.2302734\n",
      "Epoch #18\n",
      "[19,     1] train loss: 1771.2424316\n",
      "[19,     6] train loss: 1396.7056885\n",
      "[19,    11] train loss: 1370.4045410\n",
      "[19,    16] train loss: 1427.5275472\n",
      "[19,    21] train loss: 1444.6191406\n",
      "[19,    26] train loss: 1493.2639771\n",
      "[19,    31] train loss: 1427.0233154\n",
      "[19,    36] train loss: 1472.9541626\n",
      "[19,    40] train loss: 1451.6973877\n",
      "Epoch #19\n",
      "[20,     1] train loss: 1543.6271973\n",
      "[20,     6] train loss: 1384.9567057\n",
      "[20,    11] train loss: 1413.8263346\n",
      "[20,    16] train loss: 1438.2717082\n",
      "[20,    21] train loss: 1375.9523112\n",
      "[20,    26] train loss: 1454.1525269\n",
      "[20,    31] train loss: 1400.9697062\n",
      "[20,    36] train loss: 1450.7079671\n",
      "[20,    40] train loss: 1496.5252930\n",
      "Epoch #20\n",
      "[21,     1] train loss: 1723.2696533\n",
      "[21,     6] train loss: 1369.4939372\n",
      "[21,    11] train loss: 1378.7323201\n",
      "[21,    16] train loss: 1355.2185669\n",
      "[21,    21] train loss: 1515.0416463\n",
      "[21,    26] train loss: 1402.5997721\n",
      "[21,    31] train loss: 1426.6268107\n",
      "[21,    36] train loss: 1462.2772624\n",
      "[21,    40] train loss: 1487.2608643\n",
      "Epoch #21\n",
      "[22,     1] train loss: 1467.4945068\n",
      "[22,     6] train loss: 1461.8289795\n",
      "[22,    11] train loss: 1421.4773153\n",
      "[22,    16] train loss: 1393.1611125\n",
      "[22,    21] train loss: 1494.0533040\n",
      "[22,    26] train loss: 1440.4911906\n",
      "[22,    31] train loss: 1434.7485962\n",
      "[22,    36] train loss: 1424.8646240\n",
      "[22,    40] train loss: 1332.9900879\n",
      "Epoch #22\n",
      "[23,     1] train loss: 1497.3442383\n",
      "[23,     6] train loss: 1324.3249715\n",
      "[23,    11] train loss: 1384.9646606\n",
      "[23,    16] train loss: 1448.7732747\n",
      "[23,    21] train loss: 1344.4964396\n",
      "[23,    26] train loss: 1471.4816284\n",
      "[23,    31] train loss: 1324.1933390\n",
      "[23,    36] train loss: 1504.7332967\n",
      "[23,    40] train loss: 1298.9255127\n",
      "Epoch #23\n",
      "[24,     1] train loss: 1957.2956543\n",
      "[24,     6] train loss: 1438.6397095\n",
      "[24,    11] train loss: 1409.8103434\n",
      "[24,    16] train loss: 1427.3686727\n",
      "[24,    21] train loss: 1392.3115234\n",
      "[24,    26] train loss: 1433.8623657\n",
      "[24,    31] train loss: 1361.1960246\n",
      "[24,    36] train loss: 1337.5156250\n",
      "[24,    40] train loss: 1260.9666016\n",
      "Epoch #24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25,     1] train loss: 1745.5263672\n",
      "[25,     6] train loss: 1397.9055583\n",
      "[25,    11] train loss: 1345.7423299\n",
      "[25,    16] train loss: 1491.2815348\n",
      "[25,    21] train loss: 1453.5305583\n",
      "[25,    26] train loss: 1377.9437256\n",
      "[25,    31] train loss: 1482.9859416\n",
      "[25,    36] train loss: 1367.6705322\n",
      "[25,    40] train loss: 1290.0375000\n",
      "Epoch #25\n",
      "[26,     1] train loss: 1564.9383545\n",
      "[26,     6] train loss: 1376.8426107\n",
      "[26,    11] train loss: 1421.3651123\n",
      "[26,    16] train loss: 1316.1750488\n",
      "[26,    21] train loss: 1432.4721476\n",
      "[26,    26] train loss: 1426.3693034\n",
      "[26,    31] train loss: 1322.4195557\n",
      "[26,    36] train loss: 1434.4618734\n",
      "[26,    40] train loss: 1358.2436768\n",
      "Epoch #26\n",
      "[27,     1] train loss: 1756.4456787\n",
      "[27,     6] train loss: 1366.3326823\n",
      "[27,    11] train loss: 1455.9535726\n",
      "[27,    16] train loss: 1404.0227254\n",
      "[27,    21] train loss: 1318.3153280\n",
      "[27,    26] train loss: 1500.2073568\n",
      "[27,    31] train loss: 1371.3324382\n",
      "[27,    36] train loss: 1282.9675293\n",
      "[27,    40] train loss: 1405.1443359\n",
      "Epoch #27\n",
      "[28,     1] train loss: 1637.5499268\n",
      "[28,     6] train loss: 1399.7556763\n",
      "[28,    11] train loss: 1398.7185872\n",
      "[28,    16] train loss: 1437.5211995\n",
      "[28,    21] train loss: 1331.6428019\n",
      "[28,    26] train loss: 1410.1117554\n",
      "[28,    31] train loss: 1432.5332438\n",
      "[28,    36] train loss: 1400.6806641\n",
      "[28,    40] train loss: 1309.6630371\n",
      "Epoch #28\n",
      "[29,     1] train loss: 1703.0919189\n",
      "[29,     6] train loss: 1243.2013957\n",
      "[29,    11] train loss: 1361.1888021\n",
      "[29,    16] train loss: 1373.1161702\n",
      "[29,    21] train loss: 1421.7458903\n",
      "[29,    26] train loss: 1473.6040039\n",
      "[29,    31] train loss: 1396.3438721\n",
      "[29,    36] train loss: 1380.7637736\n",
      "[29,    40] train loss: 1422.5334961\n",
      "Epoch #29\n",
      "[30,     1] train loss: 1447.0415039\n",
      "[30,     6] train loss: 1481.9193319\n",
      "[30,    11] train loss: 1357.9730021\n",
      "[30,    16] train loss: 1286.4712321\n",
      "[30,    21] train loss: 1316.7964274\n",
      "[30,    26] train loss: 1409.1982422\n",
      "[30,    31] train loss: 1398.9113159\n",
      "[30,    36] train loss: 1488.3941243\n",
      "[30,    40] train loss: 1256.4135498\n",
      "Epoch #30\n",
      "[31,     1] train loss: 1587.2393799\n",
      "[31,     6] train loss: 1319.8092041\n",
      "[31,    11] train loss: 1348.4123942\n",
      "[31,    16] train loss: 1376.8274740\n",
      "[31,    21] train loss: 1316.7522583\n",
      "[31,    26] train loss: 1484.8249105\n",
      "[31,    31] train loss: 1415.0862630\n",
      "[31,    36] train loss: 1413.4878540\n",
      "[31,    40] train loss: 1397.4875732\n",
      "Epoch #31\n",
      "[32,     1] train loss: 1561.1268311\n",
      "[32,     6] train loss: 1301.7069906\n",
      "[32,    11] train loss: 1496.7720337\n",
      "[32,    16] train loss: 1395.7887980\n",
      "[32,    21] train loss: 1365.4222616\n",
      "[32,    26] train loss: 1325.1706136\n",
      "[32,    31] train loss: 1301.0159912\n",
      "[32,    36] train loss: 1418.3919271\n",
      "[32,    40] train loss: 1377.6825439\n",
      "Epoch #32\n",
      "[33,     1] train loss: 1789.0350342\n",
      "[33,     6] train loss: 1365.8657837\n",
      "[33,    11] train loss: 1339.4865316\n",
      "[33,    16] train loss: 1432.3629150\n",
      "[33,    21] train loss: 1378.8434041\n",
      "[33,    26] train loss: 1374.2953695\n",
      "[33,    31] train loss: 1344.8145142\n",
      "[33,    36] train loss: 1457.6402995\n",
      "[33,    40] train loss: 1265.0398926\n",
      "Epoch #33\n",
      "[34,     1] train loss: 1704.8751221\n",
      "[34,     6] train loss: 1312.3121541\n",
      "[34,    11] train loss: 1438.8592326\n",
      "[34,    16] train loss: 1276.8420817\n",
      "[34,    21] train loss: 1375.2350871\n",
      "[34,    26] train loss: 1363.4850260\n",
      "[34,    31] train loss: 1389.5944621\n",
      "[34,    36] train loss: 1419.5006917\n",
      "[34,    40] train loss: 1339.0050049\n",
      "Epoch #34\n",
      "[35,     1] train loss: 1551.9281006\n",
      "[35,     6] train loss: 1332.2374471\n",
      "[35,    11] train loss: 1350.8168538\n",
      "[35,    16] train loss: 1382.8315023\n",
      "[35,    21] train loss: 1350.1669108\n",
      "[35,    26] train loss: 1335.2395426\n",
      "[35,    31] train loss: 1299.6022949\n",
      "[35,    36] train loss: 1487.2654012\n",
      "[35,    40] train loss: 1451.0937988\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epoch_count = 35\n",
    "batch_size = 16\n",
    "shuffle_every_epoch = True\n",
    "    \n",
    "if shuffle_every_epoch:\n",
    "    print(f\"shuffle_every_epoch is on\")\n",
    "else:\n",
    "    print(f\"shuffle_every_epoch is off\")\n",
    "    # shuffle train and test set:\n",
    "    drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        \n",
    "for epoch in range(epoch_count):  # loop over the dataset multiple times\n",
    "    print(f\"Epoch #{epoch}\")\n",
    "    if shuffle_every_epoch:\n",
    "        # shuffle train and test set:\n",
    "        drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        \n",
    "    examples_count = len(drum_train)\n",
    "    examples_id = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    runnint_count = 0\n",
    "    batch_id = 0\n",
    "    while examples_id < examples_count:\n",
    "        batch_drum_train = drum_train[examples_id:examples_id + batch_size]\n",
    "        batch_bass_train = bass_train[examples_id:examples_id + batch_size]\n",
    "        \n",
    "        batch_bass_train_raw = torch.tensor(list(map(lambda p: p.image, batch_bass_train)), dtype=torch.float)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        bass_outputs, mu, stddev = dnb_ffnn(batch_drum_train)\n",
    "        # bass_outputs = bass_outputs.squeeze()\n",
    "        \n",
    "        # loss = criterion(bass_outputs, batch_bass_train_raw)\n",
    "        loss = 0\n",
    "        for i in range(batch_size):\n",
    "            loss += reconstruction_KL_loss_function(bass_outputs[i], batch_bass_train_raw[i], mu[i], stddev[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        runnint_count += 1\n",
    "        period = 5\n",
    "        if batch_id % period == 0 or examples_id + batch_size >= examples_count:\n",
    "            print('[%d, %5d] train loss: %.7f' %\n",
    "                  (epoch + 1, batch_id + 1, running_loss / runnint_count))\n",
    "            running_loss = 0.0\n",
    "            runnint_count = 1\n",
    "            \n",
    "        # update batch info\n",
    "        examples_id += batch_size\n",
    "        batch_id += 1\n",
    "        \n",
    "    # here we can insert measure error on test set\n",
    "\n",
    "#should check accuracy on validation set\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Этап эксплуатации нейросети\n",
    "Посмотрим на результаты, что выдаёт нейросеть на выходе..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_ffnn(drum_train)\n",
    "result = bass_outputs[0].squeeze().int()\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, более интересно посмотреть на то, что получилось в латентном пространстве... Неплохо было бы визуализировать точки в латентном пространстве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1f3/8dcnk5UECJCwg2EJIgiCREBcUJBFqaK1dWltsa1VW3H9tRa1avVb17baRbTiWmsttbVWW0RQVBYFJOyLAmEPa4BAICHrnN8fM4QJTMiELJNk3s/HYx7MPffcO5+TkPOZe+6955pzDhERiTxR4Q5ARETCQwlARCRCKQGIiEQoJQARkQilBCAiEqGiwx1AdaSkpLi0tLRwhyEi0qgsXrx4r3Mu9fjyRpUA0tLSyMzMDHcYIiKNipltCVauISARkQilBCAiEqGUAEREIpQSgIhIhFICEBGJUEoAIiIRSglARCRCKQGIiEQoJQARkQgVUgIws7FmttbMssxsUpD1t5rZSjNbZmbzzKyPv3yUmS32r1tsZiMCthnkL88ysz+amdVes0REpCpVJgAz8wCTgUuBPsD1Rzv4AG855/o55wYATwPP+Mv3Apc75/oBE4C/BmzzAnAzkO5/ja1JQ0REpHpCOQIYDGQ55zY654qBqcD4wArOubyAxUTA+cuXOud2+MtXA/FmFmdmHYAWzrn5zvdMyjeAK2vYFhERqYZQJoPrBGwLWM4GhhxfycxuA+4BYoERx68HrgaWOueKzKyTfz+B++wU7MPN7GZ8Rwp07do1hHBFRCQUoRwBBBubP+FJ8s65yc65HsAvgF9W2IFZX+Ap4Jbq7NO/3ynOuQznXEZq6gmzmYqIyCkKJQFkA10CljsDOyqpC74hovLhHDPrDLwLfN85tyFgn52rsU8REalloSSARUC6mXUzs1jgOuD9wApmlh6wOA5Y7y9PBqYB9znnPj9awTm3EzhkZkP9V/98H3ivRi0REZFqqTIBOOdKgYnADOAr4G3n3Goze9TMrvBXm2hmq81sGb7zABOOlgM9gQf9l4guM7O2/nU/AV4GsoANwPRaa5WIiFTJfBfhNA4ZGRlOTwQTEakeM1vsnMs4vlx3AouIRCglABGRCKUEICISoZQAREQilBKAiEiEUgIQEYlQSgAiIhFKCUBEJEIpAYiIRCglABGRCKUEIBJhtu0v4OCRknCHIQ2AEoBIBFm76xDDf/Mpl/9pXrhDkQZACUAkgiTFR5MQ46FTckK4Q5HjzF63hyVbcuv1M0N5JKSINBGdkhNY9cgYfI/hkEC/nf4Vz83eCMDmJ8fV62dnbt7PhFcXAbD4l5fQJimuXj5XRwAiEUadf3B/Wbil/H1pqbdeP7t1YiwGREcZ8TGeevtcHQGIiAAf33UBw576jI7J8URH1+934+6pSax+dAxRpgQgIlLv2iUnsuGJ+h36CdQstv67Yw0BiYhEKCUAEZEIpQQgIhKhlABERCKUEoCISIRSAhARiVBKACKN0OIt+xny+Mf8df7mcIcijZgSgEgjtGTLAXbnFfHJ13vCHYo0YroRTKQRmjAsjc6tEhjSvU24Q5FGTAlApBGKjY7i0n4dwh2GNHIhDQGZ2VgzW2tmWWY2Kcj6W81spZktM7N5ZtbHX97GzD41s8Nm9txx23zm3+cy/6tt7TRJRERCUWUCMDMPMBm4FOgDXH+0gw/wlnOun3NuAPA08Iy/vBB4EPhZJbv/rnNugP+lwUwRaVIOF5awdldeuMOoVChHAIOBLOfcRudcMTAVGB9YwTkX2MJEwPnL851z8/AlAhGRRutIcSnDnpjF0MdnUVBUGtI2/R+ZyZjfz+WVuZvqOLpTE0oC6ARsC1jO9pdVYGa3mdkGfEcAd4T4+a/5h38etEomKTezm80s08wyc3JyQtytiEjtWrL1ADsOFrIrr5CFm/aHtM3RTi2qgV5vGcpJ4GAdszuhwLnJwGQz+w7wS2BCFfv9rnNuu5k1B94Bvge8EWS/U4ApABkZGSd8rohIfTi3extGndEOr3Nc2Cs1pG1W/mo0uw8V0S0lqY6jOzWhJIBsoEvAcmdgx0nqTwVeqGqnzrnt/n8Pmdlb+IaaTkgAIiINQVSU8dKEjGpt0ywuhm5xMXUUUc2FcmCyCEg3s25mFgtcB7wfWMHM0gMWxwHrT7ZDM4s2sxT/+xjgG8Cq6gQuIiI1U+URgHOu1MwmAjMAD/Cqc261mT0KZDrn3gcmmtklQAmQS8Dwj5ltBloAsWZ2JTAa2ALM8Hf+HuBj4KVabZmISCXmrs9h3+Fixg/oGNHPSA7pRjDn3AfAB8eVPRTw/s6TbJtWyapBoXy2iEhtys0v5sbXFuExo22LOIb1SAl3SGHTQM9Ni4jUjaT4aHq3b05ysxi6N9CTs/VFU0GISESJ8UQx7Y4Lwh1Gg6AjABGRCKUjABFpUA4XlVJa5iXvSAkjn5lNlBmf/2IEKc3jwh1ak6MEICINRmmZlwue+oTCEi8/G92LkjIHOBZv2c+YMzX7aW1TAhCRBsPMSIj1UOZ1XDWwE0u3HiAuJorRfduHO7QmyZxrPLMrZGRkuMzMzHCHISJ1qLTMi9f5nnkgtcPMFjvnTriNWUcAItKgRHvU8dcX/aRFRCKUEoCIhEVhSSnDnpzF5X+aS2Maim5KlABEJCz+vnAbOw4UsnJ7HjsO6JlR4aAEICL1qrikDIBrMjrTJjGGHqmJdEyOD3NUkUkngUWk3lz0m0/ZvK+A2ChY9/g4Fj84OtwhRTQdAYhIvcnOLQCg2BvmQARQAhCRWpKdW8CwJ2Zxw8sLKz2pO/OuCzmtdTOe/+7Aeo5OgtEQkIjUijU78sg5XMSuvEIKS7wkxHpOqNO9bXNm33txGKKTYJQARKRWjDyjHQ9f3peurZsF7fyl4VECEJFa4Ykybhh6WrjDkGrQOQARkQilBCAiEqGUAEREIpQSgIhUy/vLdnDZH+ayIedwuEORGlICEJFqmbF6F2t25rEy+2C4Q5Ea0lVAIlItT1zdj+sHd2VYjzbhDkVqSAlARKqlRXwM56enhDsMqQUaAhKJYPvzi/nxG5nM+mp3uEORMAgpAZjZWDNba2ZZZjYpyPpbzWylmS0zs3lm1sdf3sbMPjWzw2b23HHbDPJvk2VmfzQzq50micjxnpmxlutenE+Rfyrmo5744Cs+WrObO6cuDVNkEk5VJgAz8wCTgUuBPsD1Rzv4AG855/o55wYATwPP+MsLgQeBnwXZ9QvAzUC6/zX2lFogIidVUublj59msWDTfn71/uoK6248L412zeO46fzuYYpOwimUI4DBQJZzbqNzrhiYCowPrOCcywtYTAScvzzfOTcPXyIoZ2YdgBbOufnON23gG8CVp94MEalMdJTROjEWM/jWoM4A5BwqYtv+Avp2bMm/bxvGxr2HWZ59IMyRSn0L5SRwJ2BbwHI2MOT4SmZ2G3APEAuMCGGf2cfts1MIsYhINZkZSx4cVb5c5nVc/NvPKCotY+69I/jpm0tYnn2QeVn7KtSTpi+UI4BgY/MnTPbtnJvsnOsB/AL4ZW3sE8DMbjazTDPLzMnJqTJYETm5KIOurZuR3CyWZnEerhrYCU+UMa5f+3CHJvUslCOAbKBLwHJnYMdJ6k/FN75f1T47h7JP59wUYApARkZG8KdMiEjIzIwP7rygfPnG87px43ndwhiRhEsoRwCLgHQz62ZmscB1wPuBFcwsPWBxHLD+ZDt0zu0EDpnZUP/VP98H3qtW5CIiUiNVHgE450rNbCIwA/AArzrnVpvZo0Cmc+59YKKZXQKUALnAhKPbm9lmoAUQa2ZXAqOdc2uAnwCvAwnAdP9LRETqiVX27M6GKCMjw2VmZoY7DJFG49+Ls0lLSeTs01qFOxQJIzNb7JzLOL5cU0GINFG/+fArJn+2EYDlD4+iZUJsmCOShkZTQYg0EWVlXoY9MYvhT3+Kc474mGPP5dVt9hKMjgBEmogvN+9nx0HfPZdb9hVw+8henN21FR2T42mhb/8ShBKASBMxpFtr+nVqQRTw2Adf8ePzu3Feemq4w5IGTENAIsC0FTv55OvGPSNmVFQU/739AvJLyvhozW6uf3lhuEOSBk4JQCLeyuyD3PWPpdz8xmK2HzgS7nBO8PKcjXSbNI2rJn8eUv0L/d/6T2udUJdhSROgISCJeJ1bJZDaPI5msdG0btbwxspfnrcRByzdFtpkbQ9d3pcHv9EHzbAuVVECkIjXKjGWLyaNDHcYlfr9tQP4yd+WcE3GsRlZducVkpIUhycqeCd/tPPv//CH5BWV8foPBnHR6ZrrRyrSEJBIHfl4zS4GPjqT95Ztr9F+hvZIYelDo7nvsjMAmL5yJ0Men8XQxz8mbdI0Hp+2ptJt84p8D4CZ9M6qGsUgTZMSgEgdWbrtALkFJSzeklur+42L8f3Z7j1cDMC7Syufm7FHaiJRBq//4JxajUGaBk0FIVJHiku9fLlpPxlprSrclFUbvtp5kJ++uYSiUi8vT8igT8eWtbp/aVoqmwpCRwAidSQ2Oorz01NC7vw35hzm3n8tZ+GmvVXWfWzaV2zaV8C+/GJ1/nLKlABE6oBzjvyi0mptc9c/lvF2ZjbXvriQ7bkFJ6170/ndSYrzcE1G55PWEzkZXQUkUgd63PcBXuCM9s2ZfteFIW0zuk87VmQfBMBbxdDsRb3bsuqRsTUNUyKcEoBINRWVljH08VnkF5cx657hdGnd7IQ6Xv+/63Yd4s+fruPWi3vxg9e+5MvNufzj5qGc2aklBwtKiIk2msX6/gwnjkhnUForkmI9dGmdWI8tkkilISCRajpQUEJuQQnFpV6WbQt+hc9j4/vQsXkMZcCTM9Yz4FczWLBxP8WlZazZmceevEKGPPExw5/+jDLvsW/753ZPoV9nzd0v9UNHACLV1K5FPI9c0ZddBwsZ16/jCeu37D3EA+9VvDb/SEkp//zJeXy1M4+rBnbiQEEJUWZ4oqxBTdX83CfryS0o4ZfjztCdxBFACUDkFEwYllbpuu3+KZkB+rdPZO+REr64b5RvuXMyAKnN41j0wCV4ooyoSu7mrW+b9h7mtzPXAZBxWisu7dchzBFJXdMQkEgtG9YjlXbNfXMKrdt3hKsHdQ1aLzEuutbvD6iJDi3jaZEQTXxMFAO6Joc7HKkHOgIQqQNtkuLZl19MYYmXDTn5PPfJemavy+HlCefQMiGmWvs6UlzGkZIyWifW7UR18THRrHh4TJ1+hjQsSgAip+im1xexZX8+f/vxUNo2j6+w7u83D2XtrkN0aBFP++R4xv5+Dhty8tm2v4CWnap349aoZ2ezJ6+ImXdfSFqKrg6S2qMhIJFTUFhSxsdf72H9nnxu+WvF6UlWbsulWYyHwd1a06VNM2I8Ubx50xBe+v4gnv7waz5YWfncPcHERkdhRqUzf4qcKh0BiJyC+BgP48/qwMw1uxl/1rErgb7xpzms2n4Ij8GGJ8aVl3domcAzH61jzvq9ZG7J5bIgVw9VZsZdF1Jc6iUxTn+uUrv0P0rkFP3h+rNPKNt7yDdDZ1mQG3lvOr8789bv5frBXU5ceRIxnihiPDpYl9qn2UBFQrDjwBFueGUh3zy7MxMv7llpvcLiUib9eyU/Oj9NN3RJg6HZQEVCVFpaxktzNnLoSAnZuQXc/vcl/P7jdWzMyWfyJ1kn3TY+NprfXzdQnb80ChoCkojyu5lreWvhVv7yw8GcWcnVONdMWcCSrQd4/rMs2rWI5+tdh2idEM1lZ7bn8rNCH7sXaehCOgIws7FmttbMssxsUpD1t5rZSjNbZmbzzKxPwLr7/NutNbMxAeWbA7bRuI7Uiy+y9rEvv5i1uw5VWufo3bo9U5P42l/vYGEpz98wKOS7Y5du3k/apGmkTZrG3rz8mgcuUgeqPAdgZh5gHTAKyAYWAdc759YE1GnhnMvzv78C+Klzbqw/EfwdGAx0BD4GejnnysxsM5DhnKv66Rd+OgcgNbXvcBGrduRxQc+UkKZgOPOh6Rwu9tI9pRmf/OzikD9n3B/msHqnL3ncckE37hvXp4otROpOZecAQhkCGgxkOec2+nc0FRgPlCeAo52/XyJwNKuMB6Y654qATWaW5d/f/FNqhUgNtUmKY3iv1JDrr3r0UpxzJ0yMVlBcyte7DjGwS3LQSdP+9qPBDPj1LAz4+Zhe5eX5RaXEx3h0Tb80CKEMAXUCtgUsZ/vLKjCz28xsA/A0cEcI2zpgppktNrObK/twM7vZzDLNLDMnJyeEcEVqV7AO/va3lvKtF77grS+3Bt0mOSmezU+OY9OT44iO9n3PWrhxH/0fmclVz39ep/GKhCqUBBDsq8oJ40bOucnOuR7AL4BfhrDtec65s4FLgdvMLOhjk5xzU5xzGc65jNTU0L+5idSl9HZJmBmdW534MJjK7DxYiCfK2Lb/5I97FKkvoQwBZQOBd650Bk52L/tU4IWqtnXOHf13j5m9i29oaE5oYYuEJr+olEWb93Nez5Rq3Uzl9TrKnKt0m0mXnsEvxvau1pz54wd0JLlZDD1Sk0LeRqQuhfIXsQhIN7NuZhYLXAe8H1jBzNIDFscB6/3v3weuM7M4M+sGpANfmlmimTX3b5sIjAZW1awpIie6/92V3PjaIl6cvaHSOrPX7aHguAe493tkBukPTGf9nkNs2HOIR/+7miNFJRXqVPeBKWbGRae3DfoISZFwqPIIwDlXamYTgRmAB3jVObfazB4FMp1z7wMTzewSoATIBSb4t11tZm/jO2FcCtzmvwKoHfCu/w8oGnjLOfdhHbRPItyQbq2Zsy6Hs7ocm9++pMzLln359EhNYsAjMzlY6Ov8Nz85ju9MmU/mllyK/XM5HCkq4+o/f0FJmWPJ1lz+c9v5YWmHSF0I6UYw59wHwAfHlT0U8P7Ok2z7GPDYcWUbgbOqFalIiD5ctYv4mCguOr0t3xlyGt8ZclqF9aOfmc2mfQXcMKQrBcUVv/l/sXE/AEmxHv53xwWkpSTSMTmBLfsKOPs03d0rTYvuBJYmZfuBI/zkzcUArHxkDElBZtAsKvMCUFBSxqqHx/CtF+dz98h0Au+JaZkQXT73/uyfX0xJmVcTskmTowQgTUrb5nGM6dueZnEeEmODP27x47uHszz7AEO6tSEqyvjvHReUr+uR2owt+wqYMqHiPTPq/KUp0mygIiJNnGYDFRGRCpQApFHZsOtA+SRrK7Nzwx2OSKOmBCANmnOOT77ezcacwwBc9cLC8nV3TV0SrrBEmgQlAGnQ5m/cxw9fz+S6KQso8zqSE46d2E2MiwljZCKNn64CkgatZ2oSPdsmcW73NmTtOcy2A0Xl61ZsP8SnX+1i4eZcRp7RjnPSWocxUpHGR1cBSVgUlpSx48ARuldjXhyv1/HMR+soLCnj5XmbAOjYMp4d/knWNjx+WV2FK9Ko6SogaVCuf2kBo56dwz8zt1Vd2S8qyvjk6918tGYX3xvShd7tmnPnSN8D2jsmx1eou/dwIX/5YjOlpd5ajVukKdEQkIRFSakXA4rLQu+g/7csmzX+p2x5oqL48G7fDOLfzuh6wtO9vvHHz9mVV0jmlv386fqzay1ukaZECUDCYuot57J5bz59O7Y4Yd3cdXv45+Jsnr12YIUnZ53TrU35+ysHHns4e7BHO57ZqQW78goZ2EXz94hURucApMFJmzQNgNPbJTHj7uFhjkak8dM5AGk0jn6f79lWD04RqUsaApIGJ+vxyzhcWErLZseu8y/zOrwneUKXiFSf/pokrJ796Gumr9hZocwTZRU6//zCYnrc/wHpD0xnzro99R2iSJOlIwAJm//39lLeWeJ7vPTKXqNpHh/8zt59Bccexbh820Eu7NW2XuITaeqUAKTeFZaU4TEjJenYtftZew6T3q550Ae4dG2dyD2j0tl58Ai3j0w/Yb2InBolAKlX89blcMOrXwLwyf+7kKRYIzraw7f/PJ/0ds2ZfucFQbe7Y2Sv+gxTJCIoAUi92HnwCFFmfLFxX3nZmN/PpaTM0aud72qfIJfzi0gdUgKQOldUWsbwpz8jKgpWPjyatbsO0Soxhukrd1JS5rgwPZXnv3s2nZKbATBz9S5mrtnNg+P6VDgZLCK1SwlAyg1+7CMKS7wsf3g0ZpV/HT9SXMb+gmI6JSecpE4JfR6aiQPm/Xw4g7u1JsZjRHuieOXGcwB4/Kr+lHkdCcc9u/f//reGbblHOLd7G64e1LlW2iYiJ1ICEAA+/Xonew4VA3D31KX8/iTz50x47Uu+3LSfgV2TuWNEOhf3PvGqnGXbDnD0HvM35m/lzZuGnFAnNjr4VchPfLM/s77ezei+7arfEBEJmRKAADD4tGNz6d8yvPtJ6/br1JIV2w6wdOsBfvq3xVx+VkfyjpTy8BV96NDSd1QwtHsKXVolUFBcyr2X9q5WLOenp3B+ekr1GyEi1aK5gOSULN2Sy4/+soj9AdfoP/iNPvzo/G5hjEpEgtFcQFKrBp7Wiv9MPK98+Vtnd+LqsztVax8Pv7ea66bM50hxWW2HJyIh0BCQVFtpmZeV2w/Sr1NL1jw6Bq8XkuKr/1/pveXbOVBQwu68QtJSEusgUhE5mZCOAMxsrJmtNbMsM5sUZP2tZrbSzJaZ2Twz6xOw7j7/dmvNbEyo+5TwK/M6Hnh3JS/N2VihfPKnG7jq+S94cc4GmsVGn1LnD/Dvnwzjn7eeq85fJEyq/Ms1Mw8wGRgFZAOLzOx959yagGpvOef+7K9/BfAMMNafCK4D+gIdgY/N7OgtnVXtU8Jo3vq9/PGTdXy5KReAYT3b0LdjSwAGdE2mY3I8/Tsn1+gzuqcm0T21xqGKyCkK5avbYCDLObcRwMymAuOB8s7aOZcXUD8Ryq8AHA9Mdc4VAZvMLMu/P6rap9Q/r9dL9/unA5CSGMPe/GMneF+cvYHYaA93jEhneK9Uvpg0MlxhikgtCWUIqBMQ+OTubH9ZBWZ2m5ltAJ4G7qhi25D26d/vzWaWaWaZOTk5IYQrlSksKePpD79mxupdlJR52XnwSIX1D723uvx9s1gP3xrUGY//frB1uw/xr8XZvLs0uz5DFpE6FMoRQLBbQk+4dtQ5NxmYbGbfAX4JTDjJtsEST9DrUZ1zU4Ap4LsMNIR4pRJz1uXwwmcbSIyL5ryebZi5ejev3nhO+Y1cLRKOTbvwz1uG0i45kXcW+zr8WE8UP72oB98/Ny0coYtIHQglAWQDXQKWOwM7TlJ/KvBCCNtWZ59SQ3dOXcruvEIuPbMdQ3uksCL7IBjExRzLxfeO7U2fDi3onpJIu2TfidmrBnbig5U7SYj18MJnG+iRmqTpGUSaiFASwCIg3cy6AdvxndT9TmAFM0t3zq33L44Djr5/H3jLzJ7BdxI4HfgS35HBSfcptcPrdfx62hreW+bLr2/8cDAX9krFOcevrzyT+JiK8/B846yOFZafuXYAz1w7gHv/tZyFm3Irnb5BRBqfKhOAc67UzCYCMwAP8KpzbrWZPQpkOufeByaa2SVACZCLb/gHf7238Z3cLQVuc86VAQTbZ+03T6Yu2sarn28GoGdqIud2bwOAmZ3Q+Z/MU1f3Z9KlZ9A6MbYuwhSRMNBUEE1ImddRUuat0LH/3//W8Mq8TSTEeFj60Kignf7yrQd4bPoa7rv0DAZ2bVWfIYtIPahsKgjdCdyEjPvjXDbtzeeTn11UPlXzHSPTads8jotOb1vpN/6f/2s56/Yc5t5/reCje4bXZ8giEkZKAE3Ai7M3EBcdRUFxGV7nKC3zlq9rmRDDLcN7nHT7Oy9J55H/ruGuS/S8XZFIogTQyNz/7kqmfrmVqwZ24nfXDGD9rkM8Mf1rAOb/YgSxMVG0SYqr1j7H9e/IuP4dq64oIk2KEkADV1JaxhkPfUipt2L5O0u2c+fIdLq0TiDGY0SZ0bZFHB5P8Kt0lmzNZfPefK4a2OmkT/sSkcihBNBAXfHcXFZtzyPGwwmdP0BCjJHSPI742GjWP3ZZlfv73isLyS8qo3OrZgzu1rrK+iLS9CkBNDBXTp7HiuyDeP0XZxWVBq/XOimufJqG43m9jjN/NYOC4jJe/v4gLunTnhuGnMby7AP07tC8bgIXkUZHCSDMvF4vA341nbxiSIoxDpdUvCz3otNT+O7gLgzv1ZZVW/fyt0XbeGfZHrbnFvLWl9v4wXnHnsBVWurlquc/p1mchwL/Q1Y+XLWLS/q0577Lzjjhs0vKvPxmxlp6pCZy7Tld67ahItLgKAGEWfr90zn6PKzjO3+Az9bu5alv9ic2Jpqze7RnQLd2zNs4iyPFZXz77IpTMmRuyWXlDt/ErPddejrLth3kkfFnVvrZK7IP8NKcjZjBNRlddG5AJMIoAdSz9bsPMfrZOTjg7ZuHBp0BzwOMPrMdH63ZDQ6WZR/ks1nr+c/SHbw8IYOF918SdN+Du7ViRO9UmsfHcMvwnlXG0r9zMjeel0bP1CR1/iIRSAmgju0/VMi3/jyf83q25lfj+/OnT7LKO/3/m7aGc3u04fMN+0iOg8Ml0DoO9hyB6at208ygJMponRjLnHV7KS71krl5P+f1TAn6WVFRUbx64+Cg64KJ8UTx8OV9a6GVItIYKQHUsj15hRw4UkKL+BjeXZLNUzPWArBxXwF/XZjNM9/uz+dZOezLL2Hl9jzO6tySp6/uz9gz2xMbHcWARz8s31f/ri157nvnkJIUx2s/OIf5G/bx7QzNxCkitUMJoBZ5vY4Rv5vN4cou3QEWbNrPogcuKX/y1jlprRjdtx0XPP0pXueYdfdwznt6NgBTf3J++Xa92jWnVztdwSMitUcJ4BSVlnnxRBlmxp68QhZs3M/D7606aeffLNp46ur+mBkje7dl0958OiU34zcz1lJQXEqZ1/HKvC1sfnJcPbZERCKVEkA1OOeYm7WXeetymDJ3E2Ywuk87ZqzeXaFelEH/Ti3ZkZvPnvxjCeF7w9Io9Tr2HCrk5QkZ3PfOch753xoMuHtUL579aB2vfrGZSZedUeN59ye8uoDZ6/ZhwCYlFBEJQgmgGq59cT5fbs4tX3YOFm7cV6HOwC4t+WpnHjdd2I13MrPZsyMXwVQAAAoKSURBVG5v+bq/zt/Cln1HmLF6F7FRUOS/w7dNYgzrduVxz+hetG8RXysPXVm0+YAvxhrvSUSaKj3eqRoOF5UAkJJ07KEoo89oW/7+vrG92JVXRGGp4w8fZ/FpQOcP0DYplg9X78IBxQHTO+zNL+F/K3cxOK01387oQm348M7zSU6I5oahusFLRIJTAgjRe8u2s2bnYQBm3HEBj1/Vj5sv6M67y3aW13l+9iZuGOLrcPcdLiovj/UYb988hOyDx8qm3DCIMzsk8eT4Y5dhnn7cSd412ft5dW7WSeNavf0gD7+3ivzjzj10bZPEsofH8Osr+1WzpSISKTQEFIIVW/dz59Rl5cs7DxdyTUZnSr2OaSt3sv3AERJijINHSli8NZfrzunCnHV7ABic1oq3bx0GwLs/PZcfv7GEmy5I48dvLqZjcjzXnZvGdeemnfCZxcUlXPbcfAAmf7aRxQ+ODhrb9S8tIK+wlH35xTz3nbNrueUi0pQpARxnxbZcrpj8BQAt46NZ/qsx3PefVeXr+7ZP4uH/rGbxVt8Y+7Tbh5HaPIGsnMO8Om8T94w6nT4dW9Dj/mkALNt2oHzbhZtyKfM62reIZ2TvtgzoklxpHGUBg/f5RWWV1ht5Rlv+t2Inl/XrcErtFZHIFdFDQG8u2EyP+6bxzefnlZf94LVF5e8PFvqGVV68YRDg+2H9+6fnlXf+AH+YtZ5hT8zi3cXZrNmZx6a9vmGiabefT+/2Scy464Lyun9dsIWcw0X8c/F2XrnxHG4fWfEJXCu35XL31KWUlpaSEBfDjUO70Dk5njWPjqm0Dc9eO5D1j12mBCAi1RbRD4VPv/8DSvzzLi9/eDQtE2J47pP1/HbmOgDuHtGDO0f3PmG7tEnTKt3n+LM68ofrBwZdt2DjPt5csIU7RqYHvanr6H67tE5g7r0jqt0eEZFg9FD4IL475DRen7+ZDi3jaBHv+1FMHJHOxBEnfzZu+xax7MorJjk+mjM7t2Re1j5G9WnLmL4dGNm77Qn1nXN4HQzt3oah3dtUul+P+YZ+0to0q1G7RERCEdFHADVRWFJGfIwnpLo3/WURc9bt5b+3n8/p7U8+nUNpaSnR0RGdl0WkllV2BBDR5wBqItTOH2DHgUJKvV4OHimpsq46fxGpL+pt6sHbt57LnrxCuqcmhTsUEZFySgD1ICkumiR1/iLSwGgISEQkQoWUAMxsrJmtNbMsM5sUZP09ZrbGzFaY2SwzOy1g3VNmtsr/ujag/HUz22Rmy/yvAbXTJBERCUWVCcDMPMBk4FKgD3C9mfU5rtpSIMM51x/4F/C0f9txwNnAAGAI8HMzaxGw3c+dcwP8r2WIiEi9CeUIYDCQ5Zzb6JwrBqYC4wMrOOc+dc4V+BcXAEefW9gHmO2cK3XO5QPLgbG1E7qIiNREKAmgE7AtYDnbX1aZHwHT/e+XA5eaWTMzSwEuBgLnO37MP2z0rJnFBduZmd1sZplmlpmTkxNCuCIiEopQEoAFKQt695iZ3QBkAL8BcM7NBD4AvgD+DswHjs5bfB/QGzgHaA38Itg+nXNTnHMZzrmM1NTUEMIVEZFQhJIAsqn4rb0zsOP4SmZ2CfAAcIVzrnzie+fcY/4x/lH4ksl6f/lO51MEvIZvqElEROpJKAlgEZBuZt3MLBa4Dng/sIKZDQRexNf57wko95hZG//7/kB/YKZ/uYP/XwOuBFYhIiL1psobwZxzpWY2EZgBeIBXnXOrzexRINM59z6+IZ8k4J++/pytzrkrgBhgrr8sD7jBOXd0COhvZpaK76hgGXBr7TZNRERORpPBiYg0cZoMTkREKlACEBGJUEoAIiIRSglARCRCKQGIiEQoJQARkQilBCAiEqGUAEREIpQSgIhIhFICEBGJUEoAIiIRSglARCRCKQGIiEQoJQARkQilBCAiEqGUAEREIpQSgIhIhFICEBGJUEoAIiIRqlE9E9jMcoAtQAqwN8zh1LdIa7Pa27SpvfXrNOdc6vGFjSoBHGVmmcEecNyURVqb1d6mTe1tGDQEJCISoZQAREQiVGNNAFPCHUAYRFqb1d6mTe1tABrlOQAREam5xnoEICIiNaQEICISoRpcAjCzsWa21syyzGxSkPU3mlmOmS3zv24KWPe0ma02s6/M7I9mZvUbffVV1V5/nWvMbI2/bW8FlE8ws/X+14T6i/rUnWp7zWyAmc33l60ws2vrN/JTV5PfsX9dCzPbbmbP1U/ENVPD/9NdzWym/294jZml1Vfcp6qG7Q1vn+WcazAvwANsALoDscByoM9xdW4Enguy7TDgc/8+PMB84KJwt6kW2psOLAVa+Zfb+v9tDWz0/9vK/75VuNtUh+3tBaT733cEdgLJ4W5TXbY5YP0fgLeC/b9vaK+athf4DBjlf58ENAt3m+qqvQ2hz2poRwCDgSzn3EbnXDEwFRgf4rYOiMf3S4gDYoDddRJl7QmlvT8GJjvncgGcc3v85WOAj5xz+/3rPgLG1lPcp+qU2+ucW+ecW+9/vwPYA5xwZ2MDVJPfMWY2CGgHzKyneGvqlNtrZn2AaOfcR/7yw865gvoL/ZTU5Pcb9j6roSWATsC2gOVsf9nxrvYPA/zLzLoAOOfmA5/i+2a4E5jhnPuqrgOuoVDa2wvoZWafm9kCMxtbjW0bmpq0t5yZDcb3R7OhziKtPafcZjOLAn4H/LxeIq0dNfkd9wIOmNm/zWypmf3GzDz1EHNNnHJ7G0KfFV2fHxaCYONfx1+n+l/g7865IjO7FfgLMMLMegJnAJ399T4yswudc3PqLtwaC6W90fgOIS/C17a5ZnZmiNs2NKfcXufcAQAz6wD8FZjgnPPWYay1pSa/4xuAD5xz2xrB6ayjatLeaOACYCCwFfgHviHfV+oo1tpQk/amEOY+q6EdAWQDXQKWOwM7Ais45/Y554r8iy8Bg/zvrwIW+A8bDwPTgaF1HG9NVdlef533nHMlzrlNwFp8/5lC2bahqUl7MbMWwDTgl865BfUQb22oSZvPBSaa2Wbgt8D3zezJug+5Rmr6f3qpfzilFPgPcHY9xFwTNWlv+PuscJ9EOe5kSTS+k5ndOHZCpe9xdToEvD/6AwS4FvjYv48YYBZwebjbVAvtHQv8xf8+Bd/hZht8J3834TsB3Mr/vnW421SH7Y31/07vCnc76qvNx9W5kcZxErgmv2OPv36qf91rwG3hblMdtjfsfVbYf4BBfqCXAevwje8+4C97FLjC//4JYLX/B/0p0Ntf7gFeBL4C1gDPhLsttdReA57xt2klcF3Atj8EsvyvH4S7LXXZXnzDISXAsoDXgHC3p65/xwH7aBQJoKbtBUYBK/zlrwOx4W5PXbW3IfRZmgpCRCRCNbRzACIiUk+UAEREIpQSgIhIhFICEBGJUEoAIiIRSglARCRCKQGIiESo/w/pQa/4JpAKEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    latent_train = dnb_ffnn.encoder(dnb_ffnn.get_images(drum_train), dnb_ffnn.get_conditionings(drum_train))\n",
    "    \n",
    "mu, dev = latent_train\n",
    "mu\n",
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# create data\n",
    "x = mu[:,0]*100\n",
    "y = mu[:,1]*100\n",
    "z = dev\n",
    " \n",
    "# use the scatter function\n",
    "plt.scatter(x, y, s=z*1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сохранить результаты работы сети. На anaconda нет mido, поэтому сохраняем результаты работы просто в массивчик npy... Однако, как альтернатива, его можно поставить чере pip в conda:\n",
    "https://github.com/mido/mido/issues/198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, NumpyImage, Converter\n",
    "\n",
    "\n",
    "converter = Converter((data_height, data_width))\n",
    "\n",
    "batch_drum = drum_train + drum_test + drum_validation\n",
    "batch_drum = drum_validation\n",
    "batch_bass = bass_train + bass_test + bass_validation\n",
    "batch_bass = drum_validation\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_ffnn(batch_drum)[0]\n",
    "    bass_outputs = ((bass_outputs.squeeze() + 1) / 2 > 0.55).int()\n",
    "    \n",
    "    for i in range(len(batch_drum)):\n",
    "            \n",
    "        img_dnb = np.concatenate((batch_drum[i].image,bass_outputs[i]), axis=1)\n",
    "        numpy_pair = NumpyImage(np.array(img_dnb)\n",
    "                                , batch_drum[i].tempo\n",
    "                                , batch_drum[i].instrument\n",
    "                                , 1\n",
    "                                , batch_drum[i].min_note)\n",
    "        pair = converter.convert_numpy_image_to_pair(numpy_pair)\n",
    "#         print(f\"pair.melody:{pair.melody}\")\n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/npy/sample{i+1}.mid\")\n",
    "#         np.save(f\"midi/npy/drum{i+1}.npy\", batch_drum[:,i,:].int())\n",
    "#         np.save(f\"midi/npy/bass{i+1}.npy\", bass_outputs[:,i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать градиент от двух базовых партий!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample1_id = 89\n",
    "# sample2_id = 49\n",
    "\n",
    "steps = 10 # количество шагов между семплами\n",
    "sample1_id = 55\n",
    "sample2_id = 119\n",
    "sample1 = drum_validation[sample1_id]\n",
    "sample2 = drum_validation[sample2_id]\n",
    "\n",
    "# вычисляем два вектора в латентном пространстве\n",
    "with torch.no_grad():\n",
    "    sampls = [sample1, sample2]\n",
    "    latent_train = dnb_ffnn.encoder(dnb_ffnn.get_images(sampls), dnb_ffnn.get_conditionings(sampls))\n",
    "    mu, dev = latent_train\n",
    "\n",
    "    sample1_latent = mu[0]\n",
    "    sample2_latent = mu[1]\n",
    "    \n",
    "    # пробегаемся линейно по латентному пространству\n",
    "    for step in range(steps + 1):\n",
    "        alpha = step / steps\n",
    "        latent_sample = sample1_latent + (sample2_latent - sample1_latent)*alpha\n",
    "        \n",
    "        # пока что выбираем соответствующую барабанную партию в двоичном виде\n",
    "        drum_sample = sample1\n",
    "        if (alpha >= 0.5):\n",
    "            drum_sample = sample2\n",
    "            \n",
    "        # а параметры для кондишнинга -- линейно\n",
    "        tempo = sample1.tempo + (sample2.tempo - sample1.tempo) * alpha\n",
    "        # instrument = sample1.instrument + (sample2.instrument - sample1.instrument) * alpha\n",
    "        instrument = drum_sample.instrument\n",
    "        \n",
    "        # декодируем линейную комбинацию\n",
    "        conditionings = torch.tensor([tempo, instrument]).float()\n",
    "        upsample = dnb_ffnn.decoder(latent_sample.unsqueeze(dim=0), conditionings.unsqueeze(dim=0))\n",
    "        upsample =  upsample.view((data_height, melody_width))\n",
    "        upsample = ((upsample.squeeze() + 1) / 2 > 0.55)\n",
    "        \n",
    "        \n",
    "        # сохраняем в файл\n",
    "        img_dnb = np.concatenate((drum_sample.image,upsample), axis=1)\n",
    "        numpy_pair = NumpyImage(np.array(img_dnb)\n",
    "                                , tempo\n",
    "                                , int(instrument)\n",
    "                                , 1\n",
    "                                , drum_sample.min_note)\n",
    "        pair = converter.convert_numpy_image_to_pair(numpy_pair)\n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/grad/gradient{step}.mid\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
