{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM на оригинальном датасете\n",
    "\n",
    "Попробуем сделать модель LSTM, похожую на ту, что описана в соседнем Notebook, но для нашей текущей задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем также пользовательский импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_patterns import data_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет с помощью DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# по аналогии с предыдущим примером:\n",
    "# первая строка -- ожидаемый выходной сигнал, вторая -- входные данные :)\n",
    "# dataset_train = torch.tensor([\n",
    "#     [[1,3,1,4,2,3,3,2], [1,0,0,1,8,4,7,2], [2,4,2,3,2,5,6,3]],\n",
    "#     [[2,2,1,1,4,3,4,2], [2,0,4,2,2,4,2,8], [3,5,3,4,6,1,1,2]],\n",
    "# ], dtype=torch.float)\n",
    "\n",
    "# import dataset\n",
    "drum, bass = data_conversion.make_lstm_dataset(height=64, limit=1000, patterns_file=\"decode_patterns/patterns.pairs.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# define shuffling of dataset\n",
    "def shuffle(A, B, p=0.8):\n",
    "    # take 80% to training, other to testing\n",
    "    L = len(drum)\n",
    "    idx = np.arange(L) < p*L\n",
    "    np.random.shuffle(idx)\n",
    "    yield A[idx]\n",
    "    yield B[idx]\n",
    "    yield A[np.logical_not(idx)]\n",
    "    yield B[np.logical_not(idx)]\n",
    "    \n",
    "    \n",
    "# we can select here a validation set\n",
    "drum, bass, drum_validation, bass_validation = shuffle(drum, bass)\n",
    "    \n",
    "# and we can shuffle train and test set like this:\n",
    "drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bass_train.shape, drum_train.shape, bass_test.shape, drum_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель определим в самом простом варианте, который только можно себе представить -- как в примере с конечным автоматом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем определить модель LSTM как конечный автомат\n",
    "class DrumNBassLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrumNBassLSTM, self).__init__()\n",
    "        # one input neuron, one output neuron, one layer in LSTM block\n",
    "        self.input_size = 14\n",
    "        self.hidden_size = 36\n",
    "        self.layer_count = 8\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.layer_count)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # пусть в input у нас приходит вектор размерности (64, 32, 14)\n",
    "        # то есть 64 отсчёта, тридцать два примера (минибатч), 14 значение в каждом (барабанная партия)\n",
    "        output, _ = self.lstm(input)\n",
    "        # пробуем превратить это в классификацию (для NLLLoss)\n",
    "        # output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# часть обучения\n",
    "dnb_lstm = DrumNBassLSTM()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# определим функцию потерь, которая не хочет видеть интервалы в мелодии\n",
    "def interval_penalty(melody):\n",
    "    return (melody.sum(axis=1) > 1).int().sum()\n",
    "\n",
    "# оценим также и разнообразие мелодии по её.. дисперсии?)\n",
    "# def melody_variety(melody):\n",
    "#     return 1/(1 + (melody.sum(axis=2) > 1).int())\n",
    "    \n",
    "# criterion = nn.NLLLoss() # -- этот товарищ требует, чтобы LSTM выдавал классы,\n",
    "# criterion = nn.CrossEntropyLoss() # и этот тоже\n",
    "# (числа от 0 до C-1), но как всё-таки его заставить это делать?...\n",
    "optimizer = optim.SGD(dnb_lstm.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найденные баги и их решения:\n",
    "\n",
    "https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ\n",
    "\n",
    "https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss/49209628\n",
    "\n",
    "https://stackoverflow.com/questions/56243672/expected-target-size-50-88-got-torch-size50-288-88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 300\n",
    "batch_size = 32\n",
    "shuffle_every_epoch = True\n",
    "    \n",
    "if shuffle_every_epoch:\n",
    "    print(f\"shuffle_every_epoch is on\")\n",
    "else:\n",
    "    print(f\"shuffle_every_epoch is off\")\n",
    "    # shuffle train and test set:\n",
    "    drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "    drum_train = torch.tensor(drum_train, dtype=torch.float)\n",
    "    bass_train = torch.tensor(bass_train, dtype=torch.float)\n",
    "    drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "    drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "        \n",
    "for epoch in range(epoch_count):  # loop over the dataset multiple times\n",
    "    print(f\"Epoch #{epoch}\")\n",
    "    if shuffle_every_epoch:\n",
    "        # shuffle train and test set:\n",
    "        drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        drum_train = torch.tensor(drum_train, dtype=torch.float)\n",
    "        bass_train = torch.tensor(bass_train, dtype=torch.float)\n",
    "        drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "        bass_test = torch.tensor(bass_test, dtype=torch.float)\n",
    "        \n",
    "    examples_count = drum_train.size()[0]\n",
    "    examples_id = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    runnint_count = 0\n",
    "    batch_id = 0\n",
    "    while examples_id < examples_count:\n",
    "        batch_drum_train = drum_train[examples_id:examples_id + batch_size,:,:].transpose(0,1)\n",
    "        batch_bass_train = bass_train[examples_id:examples_id + batch_size,:,:].transpose(0,1)\n",
    "        # transpose нужен для обмена размерности батча и размерности шагов\n",
    "        # print(f\"i:{i}, batch_drum_train:{batch_drum_train.size()}, batch_bass_train:{batch_bass_train.size()}\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        bass_outputs = dnb_lstm(batch_drum_train)\n",
    "        \n",
    "        loss = criterion(bass_outputs, batch_bass_train) + interval_penalty(bass_outputs)# + melody_variety(bass_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        runnint_count += 1\n",
    "        period = 5\n",
    "        if batch_id % period == 0 or examples_id + batch_size >= examples_count:\n",
    "            print('[%d, %5d] train loss: %.7f' %\n",
    "                  (epoch + 1, batch_id + 1, running_loss / runnint_count))\n",
    "            running_loss = 0.0\n",
    "            runnint_count = 1\n",
    "            \n",
    "        # update batch info\n",
    "        examples_id += batch_size\n",
    "        batch_id += 1\n",
    "        \n",
    "    # here we can insert measure error on test set\n",
    "\n",
    "#should check accuracy on validation set\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_drum_train = drum_train[:1,:,:].transpose(0,1)\n",
    "batch_bass_train = bass_train[:1,:,:].transpose(0,1)\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_lstm(batch_drum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((bass_outputs[:,:,5:12].squeeze() + 1) / 2 > 0.5).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сохранить результаты работы сети. На anaconda нет mido, поэтому сохраняем результаты работы просто в массивчик npy... Однако, как альтернатива, его можно поставить чере pip в conda:\n",
    "https://github.com/mido/mido/issues/198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, NumpyImage, Converter\n",
    "\n",
    "\n",
    "converter = Converter((64,50))\n",
    "\n",
    "batch_drum = torch.cat((drum_train, drum_test, torch.tensor(drum_validation))).transpose(0,1)\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_lstm(batch_drum)\n",
    "    bass_outputs = ((bass_outputs.squeeze() + 1) / 2 > 0.5).int()\n",
    "    \n",
    "    for i in range(bass_outputs.size()[1]):\n",
    "        img_dnb = torch.cat((batch_drum[:,i,:].int(),bass_outputs[:,i,:]), axis=1)\n",
    "        print(f\"img_dnb:{img_dnb.size()}\")\n",
    "        np_image = NumpyImage(image=img_dnb, tempo=120, instrument=34, denominator=1, min_note=24)\n",
    "        pair = converter.convert_numpy_image_to_pair(np_image)   \n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/npy/sample{i+1}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
