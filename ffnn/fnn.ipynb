{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from decode_patterns.create_images import create_images, crop_data, train_test\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO change\n",
    "batch_size = 100\n",
    "num_epochs = 200\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "limit = 10000\n",
    "\n",
    "drumnbass, _ = create_images(patterns_file=\"../patterns_pairs.tsv\", limit=limit)\n",
    "drum, bass = crop_data(drumnbass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# model class\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 128 * 14 = 1792 --> 2048\n",
    "        # веса накидываются тут\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # решение по весам\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 2048 --> 2048\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3: 2048 --> 2048\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Linear function 4 (readout): 2048 --> 128 * 36 = 4608\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=2048, out_features=4608, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model class\n",
    "\n",
    "input_dim = 128 * 14\n",
    "output_dim = 128 * 36\n",
    "hidden_dim = 2048\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate loss class\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate optimizer class\n",
    "# менять learning_rate по мере обучения\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1\n",
      "Epoch # 2\n",
      "Iteration: 100. error: 0.02036287821829319\n",
      "Epoch # 3\n",
      "Iteration: 200. error: 0.020292140543460846\n",
      "Epoch # 4\n",
      "Iteration: 300. error: 0.02011115476489067\n",
      "Epoch # 5\n",
      "Iteration: 400. error: 0.020035646855831146\n",
      "Epoch # 6\n",
      "Epoch # 7\n",
      "Iteration: 500. error: 0.020233988761901855\n",
      "Epoch # 8\n",
      "Iteration: 600. error: 0.020471399649977684\n",
      "Epoch # 9\n",
      "Iteration: 700. error: 0.01977088488638401\n",
      "Epoch # 10\n",
      "Iteration: 800. error: 0.020421497523784637\n",
      "Epoch # 11\n",
      "Epoch # 12\n",
      "Iteration: 900. error: 0.020159335806965828\n",
      "Epoch # 13\n",
      "Iteration: 1000. error: 0.020233547315001488\n",
      "Epoch # 14\n",
      "Iteration: 1100. error: 0.020211849361658096\n",
      "Epoch # 15\n",
      "Iteration: 1200. error: 0.02036159113049507\n",
      "Epoch # 16\n",
      "Epoch # 17\n",
      "Iteration: 1300. error: 0.020201439037919044\n",
      "Epoch # 18\n",
      "Iteration: 1400. error: 0.020122867077589035\n",
      "Epoch # 19\n",
      "Iteration: 1500. error: 0.020064732059836388\n",
      "Epoch # 20\n",
      "Iteration: 1600. error: 0.01993146911263466\n",
      "Epoch # 21\n",
      "Epoch # 22\n",
      "Iteration: 1700. error: 0.02007601596415043\n",
      "Epoch # 23\n",
      "Iteration: 1800. error: 0.02032945491373539\n",
      "Epoch # 24\n",
      "Iteration: 1900. error: 0.019944075495004654\n",
      "Epoch # 25\n",
      "Iteration: 2000. error: 0.02017407864332199\n",
      "Epoch # 26\n",
      "Epoch # 27\n",
      "Iteration: 2100. error: 0.020499177277088165\n",
      "Epoch # 28\n",
      "Iteration: 2200. error: 0.020144589245319366\n",
      "Epoch # 29\n",
      "Iteration: 2300. error: 0.020430609583854675\n",
      "Epoch # 30\n",
      "Iteration: 2400. error: 0.020312966778874397\n",
      "Epoch # 31\n",
      "Epoch # 32\n",
      "Iteration: 2500. error: 0.02019493468105793\n",
      "Epoch # 33\n",
      "Iteration: 2600. error: 0.020124195143580437\n",
      "Epoch # 34\n",
      "Iteration: 2700. error: 0.020134583115577698\n",
      "Epoch # 35\n",
      "Iteration: 2800. error: 0.019960545003414154\n",
      "Epoch # 36\n",
      "Epoch # 37\n",
      "Iteration: 2900. error: 0.020194070413708687\n",
      "Epoch # 38\n",
      "Iteration: 3000. error: 0.02036202885210514\n",
      "Epoch # 39\n",
      "Iteration: 3100. error: 0.020288685336709023\n",
      "Epoch # 40\n",
      "Iteration: 3200. error: 0.02049269899725914\n",
      "Epoch # 41\n",
      "Epoch # 42\n",
      "Iteration: 3300. error: 0.02018408104777336\n",
      "Epoch # 43\n",
      "Iteration: 3400. error: 0.020536959171295166\n",
      "Epoch # 44\n",
      "Iteration: 3500. error: 0.02010248228907585\n",
      "Epoch # 45\n",
      "Iteration: 3600. error: 0.020117228850722313\n",
      "Epoch # 46\n",
      "Epoch # 47\n",
      "Iteration: 3700. error: 0.02014545537531376\n",
      "Epoch # 48\n",
      "Iteration: 3800. error: 0.020260896533727646\n",
      "Epoch # 49\n",
      "Iteration: 3900. error: 0.020150648429989815\n",
      "Epoch # 50\n",
      "Iteration: 4000. error: 0.02010161802172661\n",
      "Epoch # 51\n",
      "Epoch # 52\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "l = 0\n",
    "iter = 0\n",
    "iter_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train_set, test_set = train_test(drum, bass, batch_size=batch_size, img_size=(128, 50))\n",
    "    iter_epoch += 1\n",
    "    print(f\"Epoch # {iter_epoch}\")\n",
    "    for i, (images, labels) in enumerate(zip(*train_set)):\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.view(-1, input_dim).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> MSELoss \n",
    "        k = outputs.size()\n",
    "        l = labels.view(-1, output_dim).size()\n",
    "        loss = criterion(outputs, labels.view(-1, output_dim))\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "            error = 0\n",
    "            for images, lables in zip(*test_set):\n",
    "            # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                outputs = model(images.view(-1, input_dim).to(device))\n",
    "                error += ((outputs - lables.view(-1, output_dim).to(device)) ** 2).mean()\n",
    "                # Print Loss\n",
    "            print('Iteration: {}. error: {}'.format(iter, error / test_set[1].size()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4608]) torch.Size([100, 4608])\n"
     ]
    }
   ],
   "source": [
    "print(k, l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(test_set[0].view(-1, 128 * 14).to(device))\n",
    "lables = test_set[1].view(-1, 128 * 36).to(device)\n",
    "mse_loss = ((lables[0]-outputs[0])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set, test_set = train_test(drum, bass, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model(test_set[0].view(-1, 128 * 14).to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res1 > 0.5).int() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f3cbf11691a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdrum_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "drum_set = torch.cat((train_set[0].reshape([-1, 128, 14]), test_set[0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../model_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=2048, out_features=4608, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"../model_0_state\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test(drum, bass, batch_size = batch_size)\n",
    "drum_set = torch.cat((train_set[0].reshape([-1, 128, 14]), test_set[0]), 0)\n",
    "result = []\n",
    "for d in drum_set:\n",
    "    output = (model(d.view(-1, 128 * 14).to(device)).cpu() > 0.5).float().reshape(128, 36)\n",
    "    result.append(np.array(torch.cat((d, output), 1)))\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(drum_set[1].view(-1, 32 * 14).to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, Converter\n",
    "\n",
    "converter = Converter((128,50))\n",
    "\n",
    "# batch_drum = torch.cat((drum_train, drum_test, torch.tensor(drum_validation))).transpose(0,1)\n",
    "# batch_bass = torch.cat((bass_train.int(), bass_test.int(), torch.tensor(bass_validation).int())).transpose(0,1)\n",
    "with torch.no_grad():\n",
    "\n",
    "    bass_outputs = result\n",
    "\n",
    "    for i in range(bass_outputs.shape[0]):\n",
    "        img_dnb = bass_outputs[i]\n",
    "            \n",
    "        pair = converter.convert_numpy_image_to_pair(np.array(img_dnb))\n",
    "#         print(f\"pair.melody:{pair.melody}\")\n",
    "        mid = build_track(pair, tempo=240)\n",
    "        mid.save(f\"../midi/sample{i+1}.mid\")\n",
    "#         np.save(f\"midi/npy/drum{i+1}.npy\", batch_drum[:,i,:].int())\n",
    "#         np.save(f\"midi/npy/bass{i+1}.npy\", bass_outputs[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
