{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from decode_patterns.create_images import create_images, crop_data, train_test\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "limit = 9600\n",
    "drum, bass, tempo = create_images(file_name=\"../patterns_pairs.tsv\", limit=limit)\n",
    "# drop conditionining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 128 * 14 (+16 with cond)= 1792 --> 2048\n",
    "        # веса накидываются тут\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # решение по весам\n",
    "#         nn.init.normal_(self.fc1.weight, mean=0, std=1)\n",
    "#         self.fc1.weight = nn.Parameter(self.fc1.weight * math.sqrt(input_dim/2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 2: 2048 --> 2048\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         # Non-linearity 2\n",
    "#         nn.init.normal_(self.fc2.weight, mean=0, std=1)\n",
    "#         self.fc2.weight = nn.Parameter(self.fc2.weight * math.sqrt(hidden_dim/2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3: 2048 --> 2048\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        nn.init.normal_(self.fc3.weight, mean=0, std=1)\n",
    "        self.fc3.weight = nn.Parameter(self.fc3.weight * math.sqrt(hidden_dim/2))\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Linear function 4 (readout): 2048 --> 128 * 36 = 4608\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "        nn.init.normal_(self.fc4.weight, mean=0, std=1)\n",
    "        self.fc4.weight = nn.Parameter(self.fc4.weight * math.sqrt(hidden_dim/2))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=2048, out_features=4608, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 128 * 14 \n",
    "output_dim = 128 * 36\n",
    "hidden_dim = 2048\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1\n",
      "Iteration: 100. error: 923.1240844726562\n",
      "Iteration: 200. error: 918.2725219726562\n",
      "Epoch # 2\n",
      "Iteration: 300. error: 907.4913330078125\n",
      "Iteration: 400. error: 916.2799072265625\n",
      "Epoch # 3\n",
      "Iteration: 500. error: 915.0504760742188\n",
      "Iteration: 600. error: 906.0369262695312\n",
      "Iteration: 700. error: 911.4366455078125\n",
      "Epoch # 4\n",
      "Iteration: 800. error: 916.8666381835938\n",
      "Iteration: 900. error: 915.8767700195312\n",
      "Epoch # 5\n",
      "Iteration: 1000. error: 908.9605712890625\n",
      "Iteration: 1100. error: 907.869873046875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8f847b3e4348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch # {iter_epoch}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4608\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "iter_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    (train_set, train_t), (test_set, test_t) = train_test(drum, bass, tempo, batch_size=batch_size, img_size=(128, 50))\n",
    "    iter_epoch += 1\n",
    "    print(f\"Epoch # {iter_epoch}\")\n",
    "    for i, (images, labels) in enumerate(zip(*train_set)): \n",
    "        images = images.view(-1, input_dim).requires_grad_().to(device).float()\n",
    "        labels = labels.to(device).float().reshape((32, 4608))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels.view(-1, output_dim).float())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "            error = 0\n",
    "            for img, lbl in zip(*test_set):\n",
    "            # Calculate Accuracy         \n",
    "                # Iterate through test dataset\n",
    "                out = model(img.view(-1, input_dim).to(device).float())\n",
    "                error += criterion(out.float().to(device), lbl.float().to(device))\n",
    "            print('Iteration: {}. error: {}'.format(iter, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (fc1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=2048, out_features=4608, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузить ранее обученную модель\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"../model_0_state\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить мелодии \n",
    "drum, bass, tempo = create_images(file_name=\"../patterns_pairs.tsv\", limit=limit)\n",
    "(train_set, train_tempo), (test_set, test_tempo) = train_test(drum, bass, tempo, batch_size = batch_size)\n",
    "drum_set = torch.cat((train_set[0].reshape([-1, 128 * 14]), test_set[0]), 0)\n",
    "melody_set = torch.cat((train_set[1].reshape([-1, 128, 36]), test_set[1].reshape([-1, 128, 36])), 0)\n",
    "temp_set = np.concatenate((train_tempo,test_tempo))\n",
    "result = []\n",
    "for d in drum_set:\n",
    "    output = (model(d.view(-1, 128 * 14).float().to(device)).cpu() > 0.5).float().reshape([128, 36])\n",
    "    d = d.reshape([128, 14]).float()\n",
    "    result.append(np.array(torch.cat((d, output), 1)))\n",
    "\n",
    "result = np.array(result)\n",
    "origin = []\n",
    "for i in range(len(drum_set)):\n",
    "    origin.append(np.array(torch.cat((drum_set[i].reshape([128, 14]), melody_set[i]), 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, Converter\n",
    "\n",
    "converter = Converter((128,50))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    bass_outputs = result\n",
    "\n",
    "    for i in range(0, 500):\n",
    "        img_dnb = bass_outputs[i]\n",
    "        t = temp_set[i]\n",
    "        pair = converter.convert_numpy_image_to_pair(np.array(img_dnb))\n",
    "        pair = DrumMelodyPair(pair.drum_pattern, pair.melody, tempo, t[1], pair.denominator)\n",
    "        mid = build_track(pair, tempo=t[0])\n",
    "        mid.save(f\"../midi/model_0_gen/sample{i+1}.mid\")\n",
    "    for i in range(0, 500):\n",
    "        img_dnb = origin[i]\n",
    "        t = temp_set[i]\n",
    "        pair = converter.convert_numpy_image_to_pair(np.array(img_dnb))\n",
    "        pair = DrumMelodyPair(pair.drum_pattern, pair.melody, tempo, t[1], pair.denominator)\n",
    "        mid = build_track(pair, tempo=t[0])\n",
    "        mid.save(f\"../midi/origin/sample{i+1}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
