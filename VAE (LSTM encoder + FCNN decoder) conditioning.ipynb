{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация полифонической музыки с кондишнингом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем torch и numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем также пользовательский импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_patterns import data_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_height = 64\n",
    "drum_width = 14\n",
    "melody_width = 36\n",
    "data_width = drum_width + melody_width\n",
    "data_size = data_height*data_width\n",
    "patterns_file = \"decode_patterns/patterns.pairs.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "drum, bass = data_conversion.make_lstm_dataset_conditioning(height=data_height,\n",
    "                                                            limit=1000,\n",
    "                                                            patterns_file=patterns_file,\n",
    "                                                            mono=False)\n",
    "# print(drum[0])\n",
    "# drum, bass = np.array(drum), np.array(bass)\n",
    "# print(drum[0])\n",
    "\n",
    "# define shuffling of dataset\n",
    "def shuffle(A, B, p=0.8):\n",
    "    # take 80% to training, other to testing\n",
    "    AB = list(zip(A, B))\n",
    "    L = len(AB)\n",
    "    pivot = int(p*L)\n",
    "    random.shuffle(AB)\n",
    "    yield [p[0] for p in AB[:pivot]]\n",
    "    yield [p[1] for p in AB[:pivot]]\n",
    "    yield [p[0] for p in AB[pivot:]]\n",
    "    yield [p[1] for p in AB[pivot:]]\n",
    "    \n",
    "    \n",
    "# we can select here a validation set\n",
    "drum, bass, drum_validation, bass_validation = shuffle(drum, bass)\n",
    "    \n",
    "# and we can shuffle train and test set like this:\n",
    "# drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumpyImage(image=array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), tempo=96, instrument=33, denominator=2, min_note=31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bass[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель определим в самом простом варианте, который только можно себе представить -- как в примере с конечным автоматом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder = LSTM\n",
    "# Decoder = FCNN\n",
    "class DrumNBass_LSTM_to_FCNN(nn.Module):\n",
    "    def __init__(self, bass_height, bass_width):\n",
    "        super(DrumNBass_LSTM_to_FCNN, self).__init__()\n",
    "        # save data parameters\n",
    "        self.bass_height = bass_height\n",
    "        self.bass_width = bass_width\n",
    "        self.bass_size = bass_height*bass_width\n",
    "        self.condition_size = 2 # размер подмешиваемого conditioning\n",
    "        self.embedding_size = 2 # размер латентного пространства\n",
    "        # one input neuron, one output neuron, one layer in LSTM block\n",
    "        self.input_size = 14\n",
    "        self.lstm_hidden_size = 4\n",
    "        self.lstm_layer_count = 1\n",
    "        self.lstm = nn.LSTM(self.input_size, self.lstm_hidden_size, self.lstm_layer_count)\n",
    "        self.lstm_preembed_layer = nn.Linear(self.lstm_hidden_size, 1)\n",
    "        self.lstm_embed_layer_mean = nn.Linear(self.bass_height, self.embedding_size)\n",
    "        self.lstm_embed_layer_logvar = nn.Linear(self.bass_height, self.embedding_size)\n",
    "        \n",
    "        self.decoder_layer1 = nn.Linear(self.embedding_size + self.condition_size, 48)\n",
    "        self.decoder_layer2 = nn.Linear(48 + self.condition_size, 512)\n",
    "        self.decoder_layer3 = nn.Linear(512, self.bass_size)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    def encoder(self, input):\n",
    "        # пусть в input у нас приходит вектор размерности (32, 128, 14)\n",
    "        # где имеется 32 примера (минибатч) по 128 отсчётов, 14 значений в каждом (барабанная партия)\n",
    "        # Тогда его надо транспонировать в размерность (128, 32, 14)\n",
    "        input = input.transpose(0,1)\n",
    "        output, _ = self.lstm(input)\n",
    "        output = self.sigm(self.lstm_preembed_layer(output))\n",
    "        # избавляемся от лишней размерности (embedding_size=1), чтобы получить вектор из lstm\n",
    "        # размером с высоту изображения\n",
    "        output = output.squeeze().transpose(0,1)\n",
    "        mean = self.sigm(self.lstm_embed_layer_mean(output))\n",
    "        logvar = self.sigm(self.lstm_embed_layer_logvar(output))\n",
    "        return mean, logvar\n",
    "    \n",
    "    # reference:\n",
    "    # https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    # end reference\n",
    "    \n",
    "    def decoder(self, input, cond):\n",
    "        output = torch.cat((input, cond), axis=1) # добавляем conditioning\n",
    "        output = self.sigm(self.decoder_layer1(output))\n",
    "        output = torch.cat((output, cond), axis=1) # добавляем ещё conditioning\n",
    "        output = self.sigm(self.decoder_layer2(output))\n",
    "        output = self.sigm(self.decoder_layer3(output))\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_images(input):\n",
    "        return torch.tensor(list(map(lambda p: p.image, input)), dtype=torch.float)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        images = self.get_images(input)\n",
    "        mean, logvar = self.encoder(images)\n",
    "        # генерируем случайную точку в латентном пространстве\n",
    "        result = self.reparameterize(mean, logvar)\n",
    "        # добавляем conditioning\n",
    "        conditionings = torch.tensor(list(map(lambda p: [p.tempo, p.instrument], input)), dtype=torch.float)\n",
    "        conditionings = conditionings\n",
    "        result = self.decoder(result, conditionings)\n",
    "        return result.view((-1, self.bass_height, self.bass_width)), mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# часть обучения\n",
    "dnb_lstm = DrumNBass_LSTM_to_FCNN(data_height, melody_width)\n",
    "\n",
    "# criterion = nn.MSELoss() # -- с этим всё работает (точнее, работало)\n",
    "# criterion = nn.NLLLoss() # -- этот товарищ требует, чтобы LSTM выдавал классы,\n",
    "# criterion = nn.CrossEntropyLoss() # и этот тоже\n",
    "# (числа от 0 до C-1), но как всё-таки его заставить это делать?...\n",
    "\n",
    "# оценим также и разнообразие мелодии по её.. дисперсии?)\n",
    "# def melody_variety(melody):\n",
    "#     return 1/(1 + (melody.sum(axis=2) > 1).int())\n",
    "\n",
    "# на самом деле, попробуем функцию потерь взять из VAE\n",
    "\n",
    "# Reference: https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def reconstruction_KL_loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = optim.Adam(dnb_lstm.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(dnb_lstm.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как модель форвардится на один пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 36])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_lstm.forward([drum_validation[16], drum_validation[14], drum_validation[43]])[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bass_validation[16].image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найденные баги и их решения:\n",
    "\n",
    "https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ\n",
    "\n",
    "https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss/49209628\n",
    "\n",
    "https://stackoverflow.com/questions/56243672/expected-target-size-50-88-got-torch-size50-288-88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle_every_epoch is on\n",
      "Epoch #0\n",
      "[1,     1] train loss: 52125.9023438\n",
      "[1,     6] train loss: 25525.0371094\n",
      "[1,    11] train loss: 9759.0524902\n",
      "[1,    16] train loss: 4895.7207845\n",
      "[1,    20] train loss: 3481.0973145\n",
      "Epoch #1\n",
      "[2,     1] train loss: 3720.9016113\n",
      "[2,     6] train loss: 3285.1103516\n",
      "[2,    11] train loss: 2925.7307536\n",
      "[2,    16] train loss: 2904.8113607\n",
      "[2,    20] train loss: 3110.7432129\n",
      "Epoch #2\n",
      "[3,     1] train loss: 3266.3041992\n",
      "[3,     6] train loss: 2943.2654215\n",
      "[3,    11] train loss: 2891.2506104\n",
      "[3,    16] train loss: 2909.2460124\n",
      "[3,    20] train loss: 2739.1002930\n",
      "Epoch #3\n",
      "[4,     1] train loss: 4076.9580078\n",
      "[4,     6] train loss: 2869.7117106\n",
      "[4,    11] train loss: 2744.4845785\n",
      "[4,    16] train loss: 2760.8789469\n",
      "[4,    20] train loss: 2772.6697266\n",
      "Epoch #4\n",
      "[5,     1] train loss: 3496.8679199\n",
      "[5,     6] train loss: 2704.4653727\n",
      "[5,    11] train loss: 2880.0553385\n",
      "[5,    16] train loss: 2942.2054850\n",
      "[5,    20] train loss: 2522.5009277\n",
      "Epoch #5\n",
      "[6,     1] train loss: 3376.6386719\n",
      "[6,     6] train loss: 2818.4507650\n",
      "[6,    11] train loss: 2686.6086833\n",
      "[6,    16] train loss: 2862.4838460\n",
      "[6,    20] train loss: 2638.8702148\n",
      "Epoch #6\n",
      "[7,     1] train loss: 3008.3764648\n",
      "[7,     6] train loss: 2785.9211833\n",
      "[7,    11] train loss: 2765.6284180\n",
      "[7,    16] train loss: 2718.6646729\n",
      "[7,    20] train loss: 2638.4303711\n",
      "Epoch #7\n",
      "[8,     1] train loss: 3080.3930664\n",
      "[8,     6] train loss: 2791.0775146\n",
      "[8,    11] train loss: 2705.6301270\n",
      "[8,    16] train loss: 2676.9478760\n",
      "[8,    20] train loss: 2717.8915527\n",
      "Epoch #8\n",
      "[9,     1] train loss: 3306.7524414\n",
      "[9,     6] train loss: 2668.7395833\n",
      "[9,    11] train loss: 2791.9611816\n",
      "[9,    16] train loss: 2692.6233317\n",
      "[9,    20] train loss: 2659.4849609\n",
      "Epoch #9\n",
      "[10,     1] train loss: 3054.2587891\n",
      "[10,     6] train loss: 2656.4492594\n",
      "[10,    11] train loss: 2737.4483643\n",
      "[10,    16] train loss: 2814.3932699\n",
      "[10,    20] train loss: 2686.4311035\n",
      "Epoch #10\n",
      "[11,     1] train loss: 3053.3737793\n",
      "[11,     6] train loss: 2574.2172445\n",
      "[11,    11] train loss: 2700.5088298\n",
      "[11,    16] train loss: 2796.1968180\n",
      "[11,    20] train loss: 2588.9719727\n",
      "Epoch #11\n",
      "[12,     1] train loss: 3049.8278809\n",
      "[12,     6] train loss: 2785.3450114\n",
      "[12,    11] train loss: 2581.1651204\n",
      "[12,    16] train loss: 2677.1499430\n",
      "[12,    20] train loss: 2679.4733398\n",
      "Epoch #12\n",
      "[13,     1] train loss: 3192.9645996\n",
      "[13,     6] train loss: 2682.3192139\n",
      "[13,    11] train loss: 2741.0662028\n",
      "[13,    16] train loss: 2682.1497396\n",
      "[13,    20] train loss: 2611.6792480\n",
      "Epoch #13\n",
      "[14,     1] train loss: 3513.8149414\n",
      "[14,     6] train loss: 2564.4309896\n",
      "[14,    11] train loss: 2672.1140544\n",
      "[14,    16] train loss: 2543.1274414\n",
      "[14,    20] train loss: 2726.9075684\n",
      "Epoch #14\n",
      "[15,     1] train loss: 2989.4711914\n",
      "[15,     6] train loss: 2676.1859538\n",
      "[15,    11] train loss: 2705.9381510\n",
      "[15,    16] train loss: 2664.1309408\n",
      "[15,    20] train loss: 2473.7684570\n",
      "Epoch #15\n",
      "[16,     1] train loss: 3328.2402344\n",
      "[16,     6] train loss: 2626.7072754\n",
      "[16,    11] train loss: 2714.6473796\n",
      "[16,    16] train loss: 2651.9965007\n",
      "[16,    20] train loss: 2424.0937988\n",
      "Epoch #16\n",
      "[17,     1] train loss: 2981.8737793\n",
      "[17,     6] train loss: 2622.4893799\n",
      "[17,    11] train loss: 2464.8514811\n",
      "[17,    16] train loss: 2670.4814453\n",
      "[17,    20] train loss: 2661.6036621\n",
      "Epoch #17\n",
      "[18,     1] train loss: 3366.8964844\n",
      "[18,     6] train loss: 2643.1818848\n",
      "[18,    11] train loss: 2675.8981120\n",
      "[18,    16] train loss: 2633.0204671\n",
      "[18,    20] train loss: 2496.7941895\n",
      "Epoch #18\n",
      "[19,     1] train loss: 2771.7292480\n",
      "[19,     6] train loss: 2612.4114583\n",
      "[19,    11] train loss: 2662.9156087\n",
      "[19,    16] train loss: 2573.5310059\n",
      "[19,    20] train loss: 2450.4278320\n",
      "Epoch #19\n",
      "[20,     1] train loss: 2961.2258301\n",
      "[20,     6] train loss: 2577.9147949\n",
      "[20,    11] train loss: 2610.3271891\n",
      "[20,    16] train loss: 2495.6272786\n",
      "[20,    20] train loss: 2579.1892090\n",
      "Epoch #20\n",
      "[21,     1] train loss: 3011.3610840\n",
      "[21,     6] train loss: 2565.5270182\n",
      "[21,    11] train loss: 2734.1896973\n",
      "[21,    16] train loss: 2468.4185384\n",
      "[21,    20] train loss: 2524.4066895\n",
      "Epoch #21\n",
      "[22,     1] train loss: 3318.8601074\n",
      "[22,     6] train loss: 2706.9355469\n",
      "[22,    11] train loss: 2501.9182943\n",
      "[22,    16] train loss: 2513.7174886\n",
      "[22,    20] train loss: 2603.8874512\n",
      "Epoch #22\n",
      "[23,     1] train loss: 2775.1772461\n",
      "[23,     6] train loss: 2535.5775960\n",
      "[23,    11] train loss: 2749.8955892\n",
      "[23,    16] train loss: 2602.1459147\n",
      "[23,    20] train loss: 2551.7054199\n",
      "Epoch #23\n",
      "[24,     1] train loss: 2943.5883789\n",
      "[24,     6] train loss: 2640.9786784\n",
      "[24,    11] train loss: 2564.1969808\n",
      "[24,    16] train loss: 2522.4664714\n",
      "[24,    20] train loss: 2452.0292480\n",
      "Epoch #24\n",
      "[25,     1] train loss: 2848.3579102\n",
      "[25,     6] train loss: 2564.5880941\n",
      "[25,    11] train loss: 2562.9705404\n",
      "[25,    16] train loss: 2550.7797445\n",
      "[25,    20] train loss: 2622.0332520\n",
      "Epoch #25\n",
      "[26,     1] train loss: 2909.5219727\n",
      "[26,     6] train loss: 2562.5764160\n",
      "[26,    11] train loss: 2671.3598633\n",
      "[26,    16] train loss: 2602.5425618\n",
      "[26,    20] train loss: 2396.2520508\n",
      "Epoch #26\n",
      "[27,     1] train loss: 2820.6789551\n",
      "[27,     6] train loss: 2758.0316976\n",
      "[27,    11] train loss: 2535.9154867\n",
      "[27,    16] train loss: 2532.6857910\n",
      "[27,    20] train loss: 2387.1716797\n",
      "Epoch #27\n",
      "[28,     1] train loss: 3199.5659180\n",
      "[28,     6] train loss: 2517.1333008\n",
      "[28,    11] train loss: 2579.3412272\n",
      "[28,    16] train loss: 2545.5094808\n",
      "[28,    20] train loss: 2509.9084473\n",
      "Epoch #28\n",
      "[29,     1] train loss: 2967.3017578\n",
      "[29,     6] train loss: 2579.1216634\n",
      "[29,    11] train loss: 2521.5170085\n",
      "[29,    16] train loss: 2759.4105225\n",
      "[29,    20] train loss: 2542.2762207\n",
      "Epoch #29\n",
      "[30,     1] train loss: 2753.9001465\n",
      "[30,     6] train loss: 2528.2378337\n",
      "[30,    11] train loss: 2619.1800537\n",
      "[30,    16] train loss: 2551.2525228\n",
      "[30,    20] train loss: 2395.0080078\n",
      "Epoch #30\n",
      "[31,     1] train loss: 2676.4233398\n",
      "[31,     6] train loss: 2685.2977702\n",
      "[31,    11] train loss: 2538.5153809\n",
      "[31,    16] train loss: 2493.6373698\n",
      "[31,    20] train loss: 2435.9235840\n",
      "Epoch #31\n",
      "[32,     1] train loss: 3072.3903809\n",
      "[32,     6] train loss: 2497.2967529\n",
      "[32,    11] train loss: 2613.5344645\n",
      "[32,    16] train loss: 2407.9669596\n",
      "[32,    20] train loss: 2537.8101563\n",
      "Epoch #32\n",
      "[33,     1] train loss: 2720.6896973\n",
      "[33,     6] train loss: 2585.3740641\n",
      "[33,    11] train loss: 2539.1936442\n",
      "[33,    16] train loss: 2495.1046549\n",
      "[33,    20] train loss: 2505.1086426\n",
      "Epoch #33\n",
      "[34,     1] train loss: 3073.6296387\n",
      "[34,     6] train loss: 2564.3291423\n",
      "[34,    11] train loss: 2455.9849854\n",
      "[34,    16] train loss: 2577.7667236\n",
      "[34,    20] train loss: 2337.4398437\n",
      "Epoch #34\n",
      "[35,     1] train loss: 3086.2509766\n",
      "[35,     6] train loss: 2484.8086751\n",
      "[35,    11] train loss: 2494.8001709\n",
      "[35,    16] train loss: 2599.4349772\n",
      "[35,    20] train loss: 2355.5800781\n",
      "Epoch #35\n",
      "[36,     1] train loss: 3035.0908203\n",
      "[36,     6] train loss: 2411.0948486\n",
      "[36,    11] train loss: 2676.9379476\n",
      "[36,    16] train loss: 2442.5108643\n",
      "[36,    20] train loss: 2411.9296875\n",
      "Epoch #36\n",
      "[37,     1] train loss: 3091.6335449\n",
      "[37,     6] train loss: 2442.6936849\n",
      "[37,    11] train loss: 2538.0064290\n",
      "[37,    16] train loss: 2569.9552002\n",
      "[37,    20] train loss: 2489.1255371\n",
      "Epoch #37\n",
      "[38,     1] train loss: 3077.9768066\n",
      "[38,     6] train loss: 2568.4116618\n",
      "[38,    11] train loss: 2502.4515381\n",
      "[38,    16] train loss: 2555.7807210\n",
      "[38,    20] train loss: 2427.4306152\n",
      "Epoch #38\n",
      "[39,     1] train loss: 2996.2316895\n",
      "[39,     6] train loss: 2490.5481771\n",
      "[39,    11] train loss: 2526.6357422\n",
      "[39,    16] train loss: 2572.7420247\n",
      "[39,    20] train loss: 2287.6914551\n",
      "Epoch #39\n",
      "[40,     1] train loss: 2890.9724121\n",
      "[40,     6] train loss: 2469.7798665\n",
      "[40,    11] train loss: 2488.2862956\n",
      "[40,    16] train loss: 2557.5519613\n",
      "[40,    20] train loss: 2503.2642090\n",
      "Epoch #40\n",
      "[41,     1] train loss: 3183.3542480\n",
      "[41,     6] train loss: 2381.0336100\n",
      "[41,    11] train loss: 2513.7389730\n",
      "[41,    16] train loss: 2640.0265706\n",
      "[41,    20] train loss: 2380.4975098\n",
      "Epoch #41\n",
      "[42,     1] train loss: 3209.9418945\n",
      "[42,     6] train loss: 2491.9940592\n",
      "[42,    11] train loss: 2366.6560872\n",
      "[42,    16] train loss: 2627.4922282\n",
      "[42,    20] train loss: 2352.0055664\n",
      "Epoch #42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43,     1] train loss: 3153.0776367\n",
      "[43,     6] train loss: 2511.5885824\n",
      "[43,    11] train loss: 2444.9548747\n",
      "[43,    16] train loss: 2567.3107096\n",
      "[43,    20] train loss: 2472.3983887\n",
      "Epoch #43\n",
      "[44,     1] train loss: 3339.8098145\n",
      "[44,     6] train loss: 2532.5107422\n",
      "[44,    11] train loss: 2355.7728678\n",
      "[44,    16] train loss: 2546.6046549\n",
      "[44,    20] train loss: 2375.9749512\n",
      "Epoch #44\n",
      "[45,     1] train loss: 3140.5610352\n",
      "[45,     6] train loss: 2420.6847331\n",
      "[45,    11] train loss: 2481.9594320\n",
      "[45,    16] train loss: 2507.0131836\n",
      "[45,    20] train loss: 2477.0117676\n",
      "Epoch #45\n",
      "[46,     1] train loss: 2850.5766602\n",
      "[46,     6] train loss: 2389.5799561\n",
      "[46,    11] train loss: 2596.9346517\n",
      "[46,    16] train loss: 2439.7569987\n",
      "[46,    20] train loss: 2528.6986816\n",
      "Epoch #46\n",
      "[47,     1] train loss: 3197.3476562\n",
      "[47,     6] train loss: 2394.8559570\n",
      "[47,    11] train loss: 2499.7471924\n",
      "[47,    16] train loss: 2491.4066976\n",
      "[47,    20] train loss: 2396.3103516\n",
      "Epoch #47\n",
      "[48,     1] train loss: 3272.6484375\n",
      "[48,     6] train loss: 2415.8357340\n",
      "[48,    11] train loss: 2423.6189779\n",
      "[48,    16] train loss: 2503.5199382\n",
      "[48,    20] train loss: 2467.2233887\n",
      "Epoch #48\n",
      "[49,     1] train loss: 3224.5646973\n",
      "[49,     6] train loss: 2365.1097819\n",
      "[49,    11] train loss: 2464.6772054\n",
      "[49,    16] train loss: 2414.4972331\n",
      "[49,    20] train loss: 2477.0945312\n",
      "Epoch #49\n",
      "[50,     1] train loss: 3071.3110352\n",
      "[50,     6] train loss: 2397.6636149\n",
      "[50,    11] train loss: 2520.0357666\n",
      "[50,    16] train loss: 2442.5646159\n",
      "[50,    20] train loss: 2449.5754395\n",
      "Epoch #50\n",
      "[51,     1] train loss: 2822.1450195\n",
      "[51,     6] train loss: 2427.2806803\n",
      "[51,    11] train loss: 2437.4682617\n",
      "[51,    16] train loss: 2510.4471436\n",
      "[51,    20] train loss: 2397.3634766\n",
      "Epoch #51\n",
      "[52,     1] train loss: 3175.2895508\n",
      "[52,     6] train loss: 2478.1385498\n",
      "[52,    11] train loss: 2386.5188802\n",
      "[52,    16] train loss: 2483.5886637\n",
      "[52,    20] train loss: 2298.2254883\n",
      "Epoch #52\n",
      "[53,     1] train loss: 3141.7558594\n",
      "[53,     6] train loss: 2505.1442464\n",
      "[53,    11] train loss: 2334.8861491\n",
      "[53,    16] train loss: 2558.1897380\n",
      "[53,    20] train loss: 2262.7000977\n",
      "Epoch #53\n",
      "[54,     1] train loss: 3037.2607422\n",
      "[54,     6] train loss: 2422.3454183\n",
      "[54,    11] train loss: 2421.2581380\n",
      "[54,    16] train loss: 2412.4735107\n",
      "[54,    20] train loss: 2353.1084473\n",
      "Epoch #54\n",
      "[55,     1] train loss: 3210.1181641\n",
      "[55,     6] train loss: 2405.5000814\n",
      "[55,    11] train loss: 2488.8799235\n",
      "[55,    16] train loss: 2570.0359294\n",
      "[55,    20] train loss: 2288.4603027\n",
      "Epoch #55\n",
      "[56,     1] train loss: 2876.2302246\n",
      "[56,     6] train loss: 2449.1664632\n",
      "[56,    11] train loss: 2387.6304525\n",
      "[56,    16] train loss: 2547.3743896\n",
      "[56,    20] train loss: 2316.4450195\n",
      "Epoch #56\n",
      "[57,     1] train loss: 3011.3369141\n",
      "[57,     6] train loss: 2426.5446370\n",
      "[57,    11] train loss: 2483.1924235\n",
      "[57,    16] train loss: 2393.4364421\n",
      "[57,    20] train loss: 2360.4416016\n",
      "Epoch #57\n",
      "[58,     1] train loss: 2837.0917969\n",
      "[58,     6] train loss: 2475.0425212\n",
      "[58,    11] train loss: 2302.1766357\n",
      "[58,    16] train loss: 2408.1304932\n",
      "[58,    20] train loss: 2397.8753418\n",
      "Epoch #58\n",
      "[59,     1] train loss: 2776.0732422\n",
      "[59,     6] train loss: 2480.8841960\n",
      "[59,    11] train loss: 2343.1000570\n",
      "[59,    16] train loss: 2449.3906657\n",
      "[59,    20] train loss: 2365.4821289\n",
      "Epoch #59\n",
      "[60,     1] train loss: 3076.2187500\n",
      "[60,     6] train loss: 2394.7170817\n",
      "[60,    11] train loss: 2555.3087565\n",
      "[60,    16] train loss: 2359.0172526\n",
      "[60,    20] train loss: 2303.1588379\n",
      "Epoch #60\n",
      "[61,     1] train loss: 2846.1086426\n",
      "[61,     6] train loss: 2464.8269450\n",
      "[61,    11] train loss: 2371.0170085\n",
      "[61,    16] train loss: 2465.7316488\n",
      "[61,    20] train loss: 2378.5009277\n",
      "Epoch #61\n",
      "[62,     1] train loss: 3019.3198242\n",
      "[62,     6] train loss: 2497.0231934\n",
      "[62,    11] train loss: 2464.5852458\n",
      "[62,    16] train loss: 2338.5498861\n",
      "[62,    20] train loss: 2273.8191895\n",
      "Epoch #62\n",
      "[63,     1] train loss: 2901.5747070\n",
      "[63,     6] train loss: 2395.1712646\n",
      "[63,    11] train loss: 2411.8481852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a205f0f7797a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mbass_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnb_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_drum_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;31m# bass_outputs = bass_outputs.squeeze()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8478f77ebcb9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# генерируем случайную точку в латентном пространстве\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-8478f77ebcb9>\u001b[0m in \u001b[0;36mencoder\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Тогда его надо транспонировать в размерность (128, 32, 14)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_preembed_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# избавляемся от лишней размерности (embedding_size=1), чтобы получить вектор из lstm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 526\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_count = 500\n",
    "batch_size = 32\n",
    "shuffle_every_epoch = True\n",
    "    \n",
    "if shuffle_every_epoch:\n",
    "    print(f\"shuffle_every_epoch is on\")\n",
    "else:\n",
    "    print(f\"shuffle_every_epoch is off\")\n",
    "    # shuffle train and test set:\n",
    "    drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        \n",
    "for epoch in range(epoch_count):  # loop over the dataset multiple times\n",
    "    print(f\"Epoch #{epoch}\")\n",
    "    if shuffle_every_epoch:\n",
    "        # shuffle train and test set:\n",
    "        drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        \n",
    "    examples_count = len(drum_train)\n",
    "    examples_id = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    runnint_count = 0\n",
    "    batch_id = 0\n",
    "    while examples_id < examples_count:\n",
    "        batch_drum_train = drum_train[examples_id:examples_id + batch_size]\n",
    "        batch_bass_train = bass_train[examples_id:examples_id + batch_size]\n",
    "        \n",
    "        batch_bass_train_raw = torch.tensor(list(map(lambda p: p.image, batch_bass_train)), dtype=torch.float)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        bass_outputs, mu, stddev = dnb_lstm(batch_drum_train)\n",
    "        # bass_outputs = bass_outputs.squeeze()\n",
    "        \n",
    "        # loss = criterion(bass_outputs, batch_bass_train_raw)\n",
    "        loss = 0\n",
    "        for i in range(batch_size):\n",
    "            loss += reconstruction_KL_loss_function(bass_outputs[i], batch_bass_train_raw[i], mu[i], stddev[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        runnint_count += 1\n",
    "        period = 5\n",
    "        if batch_id % period == 0 or examples_id + batch_size >= examples_count:\n",
    "            print('[%d, %5d] train loss: %.7f' %\n",
    "                  (epoch + 1, batch_id + 1, running_loss / runnint_count))\n",
    "            running_loss = 0.0\n",
    "            runnint_count = 1\n",
    "            \n",
    "        # update batch info\n",
    "        examples_id += batch_size\n",
    "        batch_id += 1\n",
    "        \n",
    "    # here we can insert measure error on test set\n",
    "\n",
    "#should check accuracy on validation set\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Этап эксплуатации нейросети\n",
    "Посмотрим на результаты, что выдаёт нейросеть на выходе..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_lstm(drum_train)\n",
    "result = bass_outputs[0].squeeze().int()\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, более интересно посмотреть на то, что получилось в латентном пространстве... Неплохо было бы визуализировать точки в латентном пространстве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    latent_train = dnb_lstm.encoder(dnb_lstm.get_images(drum_train))\n",
    "    \n",
    "mu, dev = latent_train\n",
    "\n",
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# create data\n",
    "x = mu[:,0]\n",
    "y = mu[:,1]\n",
    "z = dev\n",
    " \n",
    "# use the scatter function\n",
    "plt.scatter(x, y, s=z*20, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сохранить результаты работы сети. На anaconda нет mido, поэтому сохраняем результаты работы просто в массивчик npy... Однако, как альтернатива, его можно поставить чере pip в conda:\n",
    "https://github.com/mido/mido/issues/198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, NumpyImage, Converter\n",
    "\n",
    "\n",
    "converter = Converter((data_height, data_width))\n",
    "\n",
    "batch_drum = drum_train + drum_test + drum_validation\n",
    "batch_drum = drum_validation\n",
    "batch_bass = bass_train + bass_test + bass_validation\n",
    "batch_bass = drum_validation\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_lstm(batch_drum)[0]\n",
    "    bass_outputs = ((bass_outputs.squeeze() + 1) / 2 > 0.55).int()\n",
    "    \n",
    "    for i in range(len(batch_drum)):\n",
    "            \n",
    "        img_dnb = np.concatenate((batch_drum[i].image,bass_outputs[i]), axis=1)\n",
    "        numpy_pair = NumpyImage(np.array(img_dnb)\n",
    "                                , batch_drum[i].tempo\n",
    "                                , batch_drum[i].instrument\n",
    "                                , 1\n",
    "                                , batch_drum[i].min_note)\n",
    "        pair = converter.convert_numpy_image_to_pair(numpy_pair)\n",
    "#         print(f\"pair.melody:{pair.melody}\")\n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/npy/sample{i+1}.mid\")\n",
    "#         np.save(f\"midi/npy/drum{i+1}.npy\", batch_drum[:,i,:].int())\n",
    "#         np.save(f\"midi/npy/bass{i+1}.npy\", bass_outputs[:,i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать градиент от двух базовых партий!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "steps = 10 # количество шагов между семплами\n",
    "sample1_id = 3\n",
    "sample2_id = 49\n",
    "sample1 = drum_validation[sample1_id]\n",
    "sample2 = drum_validation[sample2_id]\n",
    "\n",
    "# вычисляем два вектора в латентном пространстве\n",
    "with torch.no_grad():\n",
    "    latent_train = dnb_lstm.encoder(dnb_lstm.get_images([sample1, sample2]))\n",
    "    mu, dev = latent_train\n",
    "\n",
    "    sample1_latent = mu[0]\n",
    "    sample2_latent = mu[1]\n",
    "    \n",
    "    # пробегаемся линейно по латентному пространству\n",
    "    for step in range(steps + 1):\n",
    "        alpha = step / steps\n",
    "        latent_sample = sample1_latent + (sample2_latent - sample1_latent)*alpha\n",
    "        \n",
    "        # пока что выбираем соответствующую барабанную партию в двоичном виде\n",
    "        drum_sample = sample1\n",
    "        if (alpha >= 0.5):\n",
    "            drum_sample = sample2\n",
    "            \n",
    "        # а параметры для кондишнинга -- линейно\n",
    "        tempo = sample1.tempo + (sample2.tempo - sample1.tempo) * alpha\n",
    "        instrument = sample1.instrument + (sample2.instrument - sample1.instrument) * alpha\n",
    "        \n",
    "        # декодируем линейную комбинацию\n",
    "        conditionings = torch.tensor([tempo, instrument]).float()\n",
    "        upsample = dnb_lstm.decoder(latent_sample.unsqueeze(dim=0), conditionings.unsqueeze(dim=0))\n",
    "        upsample =  upsample.view((data_height, melody_width))\n",
    "        upsample = ((upsample.squeeze() + 1) / 2 > 0.55)\n",
    "        \n",
    "        \n",
    "        # сохраняем в файл\n",
    "        img_dnb = np.concatenate((drum_sample.image,upsample), axis=1)\n",
    "        numpy_pair = NumpyImage(np.array(img_dnb)\n",
    "                                , tempo\n",
    "                                , instrument\n",
    "                                , 1\n",
    "                                , drum_sample.min_note)\n",
    "        pair = converter.convert_numpy_image_to_pair(numpy_pair)\n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/grad/gradient{step}.mid\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
