{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "Попытка сделать монофонический выход из сетки. Аналогично LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем также пользовательский импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_patterns import data_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "drum, bass = data_conversion.make_lstm_dataset(height=16, limit=1000, patterns_file=\"decode_patterns/patterns.pairs.tsv\", mono=True)\n",
    "\n",
    "\n",
    "# define shuffling of dataset\n",
    "def shuffle(A, B, p=0.8):\n",
    "    # take 80% to training, other to testing\n",
    "    L = len(A)\n",
    "    idx = np.arange(L) < p*L\n",
    "    np.random.shuffle(idx)\n",
    "    yield A[idx]\n",
    "    yield B[idx]\n",
    "    yield A[np.logical_not(idx)]\n",
    "    yield B[np.logical_not(idx)]\n",
    "    \n",
    "    \n",
    "# we can select here a validation set\n",
    "drum, bass, drum_validation, bass_validation = shuffle(drum, bass)\n",
    "    \n",
    "# and we can shuffle train and test set like this:\n",
    "drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bass_validation[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем определить модель LSTM как конечный автомат\n",
    "class DrumNBassGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DrumNBassGRU, self).__init__()\n",
    "        # one input neuron, one output neuron, one layer in LSTM block\n",
    "        self.input_size = 14\n",
    "        self.hidden_size = 34\n",
    "        self.layer_count = 1\n",
    "        self.lstm = nn.GRU(self.input_size, self.hidden_size, self.layer_count)\n",
    "        self.embed_layer = nn.Linear(self.hidden_size, 1)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # пусть в input у нас приходит вектор размерности (64, 32, 14)\n",
    "        # то есть 64 отсчёта, тридцать два примера (минибатч), 14 значение в каждом (барабанная партия)\n",
    "        output, _ = self.lstm(input)\n",
    "        output = self.sigm(self.embed_layer(output))*37\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# часть обучения\n",
    "dnb_gru = DrumNBassGRU()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# оценим также и разнообразие мелодии по её.. дисперсии?)\n",
    "# def melody_variety(melody):\n",
    "#     return 1/(1 + (melody.sum(axis=2) > 1).int())\n",
    "    \n",
    "# criterion = nn.NLLLoss() # -- этот товарищ требует, чтобы LSTM выдавал классы,\n",
    "# criterion = nn.CrossEntropyLoss() # и этот тоже\n",
    "# (числа от 0 до C-1), но как всё-таки его заставить это делать?...\n",
    "# optimizer = optim.SGD(dnb_lstm.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(dnb_gru.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найденные баги и их решения:\n",
    "\n",
    "https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ\n",
    "\n",
    "https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss/49209628\n",
    "\n",
    "https://stackoverflow.com/questions/56243672/expected-target-size-50-88-got-torch-size50-288-88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 500\n",
    "batch_size = 128\n",
    "shuffle_every_epoch = True\n",
    "    \n",
    "if shuffle_every_epoch:\n",
    "    print(f\"shuffle_every_epoch is on\")\n",
    "else:\n",
    "    print(f\"shuffle_every_epoch is off\")\n",
    "    # shuffle train and test set:\n",
    "    drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "    drum_train = torch.tensor(drum_train, dtype=torch.float)\n",
    "    bass_train = torch.tensor(bass_train, dtype=torch.float)\n",
    "    drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "    drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "        \n",
    "for epoch in range(epoch_count):  # loop over the dataset multiple times\n",
    "    print(f\"Epoch #{epoch}\")\n",
    "    if shuffle_every_epoch:\n",
    "        # shuffle train and test set:\n",
    "        drum_train, bass_train, drum_test, bass_test = shuffle(drum, bass)\n",
    "        drum_train = torch.tensor(drum_train, dtype=torch.float)\n",
    "        bass_train = torch.tensor(bass_train, dtype=torch.float)\n",
    "        drum_test = torch.tensor(drum_test, dtype=torch.float)\n",
    "        bass_test = torch.tensor(bass_test, dtype=torch.float)\n",
    "        \n",
    "    examples_count = drum_train.size()[0]\n",
    "    examples_id = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    runnint_count = 0\n",
    "    batch_id = 0\n",
    "    while examples_id < examples_count:\n",
    "        batch_drum_train = drum_train[examples_id:examples_id + batch_size,:,:].transpose(0,1)\n",
    "        batch_bass_train = bass_train[examples_id:examples_id + batch_size,].transpose(0,1)\n",
    "        # transpose нужен для обмена размерности батча и размерности шагов\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        bass_outputs = dnb_gru(batch_drum_train).squeeze()\n",
    "        \n",
    "        # loss = criterion(bass_outputs, batch_bass_train.long())\n",
    "        loss = criterion(bass_outputs, batch_bass_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        runnint_count += 1\n",
    "        period = 5\n",
    "        if batch_id % period == 0 or examples_id + batch_size >= examples_count:\n",
    "            print('[%d, %5d] train loss: %.7f' %\n",
    "                  (epoch + 1, batch_id + 1, running_loss / runnint_count))\n",
    "            running_loss = 0.0\n",
    "            runnint_count = 1\n",
    "            \n",
    "        # update batch info\n",
    "        examples_id += batch_size\n",
    "        batch_id += 1\n",
    "        \n",
    "    # here we can insert measure error on test set\n",
    "\n",
    "#should check accuracy on validation set\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_drum_train = drum_train[:,:,:].transpose(0,1)\n",
    "batch_bass_train = bass_train[:,:].transpose(0,1)\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_gru(batch_drum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bass_outputs.squeeze().int()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сохранить результаты работы сети. На anaconda нет mido, поэтому сохраняем результаты работы просто в массивчик npy... Однако, как альтернатива, его можно поставить чере pip в conda:\n",
    "https://github.com/mido/mido/issues/198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "from decode_patterns.data_conversion import build_track, DrumMelodyPair, NumpyImage, Converter\n",
    "\n",
    "\n",
    "converter = Converter((16,50))\n",
    "\n",
    "batch_drum = torch.cat((drum_train, drum_test, torch.tensor(drum_validation))).transpose(0,1)\n",
    "batch_bass = torch.cat((bass_train.int(), bass_test.int(), torch.tensor(bass_validation).int())).transpose(0,1)\n",
    "with torch.no_grad():\n",
    "    bass_outputs = dnb_gru(batch_drum)\n",
    "    bass_outputs = bass_outputs.squeeze().int()\n",
    "    \n",
    "    for i in range(bass_outputs.size()[1]):\n",
    "        bass_seq = bass_outputs[:,i]\n",
    "        bass_output = []\n",
    "        for bass_note in bass_seq:\n",
    "            bass_row = np.eye(1, 36, bass_note - 1)[0]\n",
    "            bass_output.append(bass_row)\n",
    "        bass_output = torch.tensor(bass_output).int().squeeze()\n",
    "        \n",
    "            \n",
    "        img_dnb = torch.cat((batch_drum[:,i,:].int(),bass_output), axis=1)\n",
    "        numpy_pair = NumpyImage(np.array(img_dnb), 120, 1, 1, 36)\n",
    "        pair = converter.convert_numpy_image_to_pair(numpy_pair)\n",
    "        mid = build_track(pair, tempo=pair.tempo)\n",
    "        mid.save(f\"midi/npy/sample{i+1}.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
